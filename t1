"@proceedings{ 10.1109/HICSS.2001.927053,\n author = {D. McKnight And N.L. Chervany},\n doi = {http://doi.ieeecomputersociety.org/10.1109/HICSS.2001.927053},\n issn = {1530-1605},\n journal = {Hawaii International Conference on System Sciences},\n pages = {7022--7031},\n publisher = {IEEE Computer Society},\n title = {Conceptualizing Trust: A Typology and E-Commerce Customer Relationships Model},\n volume = {7},\n year = {2001}\n}\n\n@inproceedings{ 1298431,\n address = {New York, NY, USA},\n author = {Yuangui Lei and Victoria Uren and Enrico Motta},\n booktitle = {K-CAP '07: Proceedings of the 4th international conference on Knowledge capture},\n citeulike-article-id = {6544743},\n citeulike-linkout-0 = {http://dx.doi.org/http://doi.acm.org/10.1145/1298406.1298431},\n doi = {http://doi.acm.org/10.1145/1298406.1298431},\n link = {http://dx.doi.org/http://doi.acm.org/10.1145/1298406.1298431},\n location = {Whistler, BC, Canada},\n pages = {135--142},\n posted-at = {2010-01-15 17:40:03},\n priority = {2},\n publisher = {ACM},\n title = {A framework for evaluating semantic metadata}\n}\n\n@inproceedings{ 1670651,\n author = {Qing Zou and Wei Fan},\n booktitle = {DCMI '09: Proceedings of the 2009 International Conference on Dublin Core and Metadata Applications},\n location = {Seoul, Korea},\n pages = {107--112},\n title = {A semantic MediaWiki-empowered terminology registry},\n year = {2009}\n}\n\n@inproceedings{ 4721453,\n author = {Yaobin Lu and Ling Zhao and Bin Wang},\n doi = {10.1109/AMIGE.2008.ECP.11},\n journal = {Advanced Management of Information for Globalized Enterprises, 2008. AMIGE 2008. IEEE Symposium on},\n keyword = {consumer purchase decision-making process, consumers' behaviors, information intention, purchase behavior, purchase intention, trust building mechanisms, virtual communities, decision making, information networks, purchasing},\n month = {sept.},\n number = {},\n pages = {1--5},\n title = {Exploring Factors Affecting Trust and Purchase Behavior in Virtual Communities},\n volume = {},\n year = {2008}\n}\n\n@article{ 984325,\n author = {Marcos Andr{\\'e} Gon\\c{c}alves and Edward A. Fox and Layne T. Watson and Neill A. Kipp},\n doi = {http://doi.acm.org/10.1145/984321.984325},\n issn = {1046-8188},\n journal = {ACM Trans. Inf. Syst.},\n number = {2},\n pages = {270--312},\n publisher = {ACM},\n title = {Streams, structures, spaces, scenarios, societies (5s): A formal model for digital libraries},\n volume = {22},\n year = {2004}\n}\n\n@article{ citeulike6580903,\n abstract = {this paper, we want to exploit this similarity to apply reasoning techniques from description logics to semi-structured data.},\n author = {V. Informatik and D. Michaeli and W. Nutt and Y. Sagiv and David Michaeli and Y. {Werner Nutt}},\n citeulike-article-id = {6580903},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.2855},\n keyword = {description\\_logics, logic, semi-structure},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.2855},\n posted-at = {2010-01-22 20:55:44},\n priority = {2},\n title = {Classification Rules for Semi-Structured Data}\n}\n\n@article{ citeulike6581132,\n abstract = {Recent proposals to improve the quality of interaction with the World Wide Web suggest considering the Web as a huge semi-structured database, so that retrieving information can be supported by the task of database querying. Under this view, it is important to represent the form of both the network, and the documents placed in the nodes of the network. However, the current proposals do not pay sufficient attention to represent document structures and reasoning about them. In this paper, we address these problems by providing a framework where Document Type Definitions (DTDs) expressed in the eXtensible Markup Language (XML) are formalized in an expressive Description Logic equipped with sound and complete inference algorithms. We provide methods for verifying conformance of a document to a DTD in polynomial time, and structural equivalence of DTDs in worst case deterministic exponential time, improving known algorithms for this problem which were double exponential. We also deal with pa...},\n author = {Diego Calvanese and Giuseppe D. Giacomo and Maurizio Lenzerini},\n citeulike-article-id = {6581132},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.6641},\n journal = {Journal of Logic and Computation},\n keyword = {description\\_logic\\_approach, document\\_structures},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.6641},\n pages = {295--318},\n posted-at = {2010-01-22 21:51:43},\n priority = {2},\n title = {Representing and Reasoning on XML Documents: A Description Logic Approach},\n volume = {9}\n}\n\n@article{ citeulike:1003673,\n author = {Stephen Downes},\n citeulike-article-id = {1003673},\n citeulike-linkout-0 = {http://www-jime.open.ac.uk/2004/5/downes-2004-5-disc-t.html},\n journal = {Journal of Interactive Media in Education},\n keyword = {metadata},\n link = {http://www-jime.open.ac.uk/2004/5/downes-2004-5-disc-t.html},\n number = {5},\n posted-at = {2009-12-02 00:29:53},\n priority = {0},\n title = {Resource Profiles},\n year = {2004}\n}\n\n@article{ citeulike:1019370,\n abstract = {This article presents the semantic portal MuseumFinland for publishing heterogeneous museum collections on the Semantic Web. It is shown how museums with their semantically rich and interrelated collection content can create a large, consolidated semantic collection portal together on the web. By sharing a set of ontologies, it is possible to make collections semantically interoperable, and provide the museum visitors with intelligent content-based search and browsing services to the global collection base. The architecture underlying MuseumFinland separates generic search and browsing services from the underlying application dependent schemas and metadata by a layer of logical rules. As a result, the portal creation framework and software developed has been applied successfully to other domains as well. MuseumFinland got the Semantic Web Challence Award (second prize) in 2004.},\n author = {E. Hyvonen and E. Makela and M. Salminen and A. Valo and K. Viljanen and S. Saarela and M. Junnila and S. Kettula},\n booktitle = {Selcted Papers from the International Semantic Web Conference, 2004 - ISWC, 2004},\n citeulike-article-id = {1019370},\n citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.websem.2005.05.008},\n citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S157082680500017X},\n citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B758F-4GXVGBB-1/2/31b4fa1159b5bb40335853c6c25ecd50},\n doi = {10.1016/j.websem.2005.05.008},\n issn = {15708268},\n journal = {Web Semantics: Science, Services and Agents on the World Wide Web},\n keyword = {museum, ontology, semantic\\_web},\n link = {http://dx.doi.org/10.1016/j.websem.2005.05.008},\n month = {October},\n number = {2-3},\n pages = {224--241},\n posted-at = {2010-01-15 02:37:08},\n priority = {0},\n title = {MuseumFinland—Finnish museums on the semantic web},\n volume = {3},\n year = {2005}\n}\n\n@book{ citeulike:108696,\n abstract = {<i>Practical RDF</i> explains RDF from the ground up, providing real-world examples and descriptions of how the technology is being used in applications like Mozilla, FOAF, and Chandler, as well as infrastructure you can use to build your own applications. This book cuts to the heart of the W3C's often obscure specifications, giving you tools to apply RDF successfully in your own projects. The first part of the book focuses on the RDF specifications. After an introduction to RDF, the book covers the RDF specification documents themselves, including RDF Semantics and Concepts and Abstract Model specifications, RDF constructs, and the RDF Schema. The second section focuses on programming language support, and the tools and utilities that allow developers to review, edit, parse, store, and manipulate RDF/XML. Subsequent sections focus on RDF's data roots, programming and framework support, and practical implementation and use of RDF and RDF/XML. If you want to know how to apply RDF to information processing, <i>Practical RDF</i> is for you. Whether your interests lie in large-scale information aggregation and analysis or in smaller-scale projects like weblog syndication, this book will provide you with a solid foundation for working with RDF. },\n author = {Shelley Powers},\n citeulike-article-id = {108696},\n howpublished = {Paperback},\n isbn = {0596002637},\n keyword = {rdf},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0596002637},\n month = {August},\n posted-at = {2009-06-30 20:12:47},\n priority = {0},\n publisher = {O'Reilly},\n title = {Practical RDF}\n}\n\n@book{ citeulike:111664,\n abstract = {Mining the Web: Discovering Knowledge from Hypertext Data is the first book devoted entirely to techniques for producing knowledge from the vast body of unstructured Web data. Building on an initial survey of infrastructural issuesincluding Web crawling and indexingChakrabarti examines low-level machine learning techniques as they relate specifically to the challenges of Web mining. He then devotes the final part of the book to applications that unite infrastructure and analysis to bring machine learning to bear on systematically acquired and stored data. Here the focus is on results: the strengths and weaknesses of these applications, along with their potential as foundations for further progress. From Chakrabarti's workpainstaking, critical, and forward-lookingreaders will gain the theoretical and practical understanding they need to contribute to the Web mining effort.<br><br>* A comprehensive, critical exploration of statistics-based attempts to make sense of Web Mining.<br>* Details the special challenges associated with analyzing unstructured and semi-structured data.<br>* Looks at how classical Information Retrieval techniques have been modified for use with Web data.<br>* Focuses on today's dominant learning methods: clustering and classification, hyperlink analysis, and supervised and semi-supervised learning.<br>* Analyzes current applications for resource discovery and social network analysis.<br>* An excellent way to introduce students to especially vital applications of data mining and machine learning technology.</li></ul>},\n author = {Soumen Chakrabarti},\n citeulike-article-id = {111664},\n howpublished = {Hardcover},\n isbn = {1558607544},\n keyword = {information\\_retrieval},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/1558607544},\n month = {August},\n posted-at = {2009-06-30 20:15:13},\n priority = {2},\n publisher = {Morgan Kaufmann},\n title = {Mining the Web: Analysis of Hypertext and Semi Structured Data}\n}\n\n@inproceedings{ citeulike:1126745,\n abstract = {This paper challenges some of the assumptions underlying the metadata creation process in the context of two communities of practice, based around learning object repositories and open e- Print archives. The importance of quality assurance for metadata creation is discussed and evidence from the literature, from the practical experiences of repositories and archives, and from related research and practices within other communities is presented. Issues for debate and further investigation are identified, formulated as a series of key research questions. Although there is much work to be done in the area of quality assurance for metadata creation, this paper represents an important first step towards a fuller understanding of the subject.},\n author = {Jane Barton and Sarah Currier and Jessie M. N. Hey},\n citeulike-article-id = {1126745},\n citeulike-linkout-0 = {http://dcpapers.dublincore.org/ojs/pubs/article/view/732/728},\n citeulike-linkout-1 = {http://www.siderean.com/dc2003/201\\\\_paper60.pdf},\n keyword = {metadata\\_creation, metadata\\_quality},\n link = {http://dcpapers.dublincore.org/ojs/pubs/article/view/732/728},\n pages = {29--36},\n posted-at = {2010-01-07 13:53:50},\n priority = {0},\n publisher = {DCMI},\n title = {Building Quality Assurance into Metadata Creation: an Analysis based on the Learning Objects and e-Prints Communities of Practice}\n}\n\n@article{ citeulike:1202321,\n abstract = {This paper provides a history and overview of the field of human information behavior, including recent advances in the field and multidisciplinaryperspectives.Keywords: human information behavior, information seeking, research, user studies.IntroductionUntil recently the computer science and information systemscommunities have equated `information requirements' of userswith the way users behave in relation to the systems available.In other words, investigations into information...},\n author = {T. D. Wilson},\n citeulike-article-id = {1202321},\n citeulike-linkout-0 = {http://citeseer.ist.psu.edu/403930.html},\n citeulike-linkout-1 = {http://citeseer.lcs.mit.edu/403930.html},\n citeulike-linkout-2 = {http://citeseer.ifi.unizh.ch/403930.html},\n citeulike-linkout-3 = {http://citeseer.comp.nus.edu.sg/403930.html},\n journal = {Informing Science},\n keyword = {information\\_behaviour},\n link = {http://citeseer.ist.psu.edu/403930.html},\n number = {2},\n pages = {49--56},\n posted-at = {2009-09-15 23:38:47},\n priority = {3},\n title = {Human information behavior},\n volume = {3},\n year = {2000}\n}\n\n@article{ citeulike:1209626,\n author = {Eun G. Park and Qing Zou and David Mcknight},\n citeulike-article-id = {1209626},\n doi = {10.1108/00330330710724917},\n issn = {0033-0337},\n journal = {Program: electronic library \\& information systems},\n keyword = {etd},\n link = {http://dx.doi.org/10.1108/00330330710724917},\n number = {1},\n pages = {81--91},\n posted-at = {2008-06-01 21:32:53},\n priority = {0},\n publisher = {Emerald Group Publishing Limited},\n title = {Electronic thesis initiative: pilot project of McGill University, Montreal},\n volume = {41},\n year = {2007}\n}\n\n@article{ citeulike:1216193,\n address = {Secaucus, NJ, USA},\n author = {Latifur Khan and Dennis Mcleod and Eduard Hovy},\n citeulike-article-id = {1216193},\n doi = {10.1007/s00778-003-0105-1},\n issn = {1066-8888},\n journal = {The VLDB Journal},\n keyword = {ontology},\n link = {http://dx.doi.org/10.1007/s00778-003-0105-1},\n month = {January},\n number = {1},\n pages = {71--85},\n posted-at = {2009-06-30 11:52:57},\n priority = {2},\n publisher = {Springer-Verlag New York, Inc.},\n title = {Retrieval effectiveness of an ontology-based model for information selection},\n volume = {13},\n year = {2004}\n}\n\n@book{ citeulike:1217375,\n author = {Baden Hughes},\n citeulike-article-id = {1217375},\n journal = {: Digital Libraries: International Collaboration and Cross-Fertilization},\n keyword = {evaluation, metadata, metadata\\_quality},\n link = {http://www.springerlink.com/content/4kaxeu5p2fb2nac1},\n pages = {320--329},\n posted-at = {2009-07-01 20:59:54},\n priority = {3},\n title = {Metadata Quality Evaluation: Experience from the Open Language Archives Community}\n}\n\n@article{ citeulike:1371245,\n abstract = {Document keyphrases provide a concise summary of a document's content, offering semantic metadata summarizing a document. They can be used in many applications related to knowledge management and text mining, such as automatic text summarization, development of search engines, document clustering, document classification, thesaurus construction, and browsing interfaces. Because only a small portion of documents have keyphrases assigned by authors, and it is time-consuming and costly to manually assign keyphrases to documents, it is necessary to develop an algorithm to automatically generate keyphrases for documents. This paper describes a Keyphrase Identification Program (KIP), which extracts document keyphrases by using prior positive samples of human identified phrases to assign weights to the candidate keyphrases. The logic of our algorithm is: The more keywords a candidate keyphrase contains and the more significant these keywords are, the more likely this candidate phrase is a keyphrase. KIP's learning function can enrich the glossary database by automatically adding new identified keyphrases to the database. KIP's personalization feature will let the user build a glossary database specifically suitable for the area of his/her interest. The evaluation results show that KIP's performance is better than the systems we compared to and that the learning function is effective.},\n address = {Information Systems Department, New Jersey Institute of Technology, Newark, NJ 07102},\n author = {Yi-Fang B. Wu and Quanzhi Li and Razvan S. Bot and Xin Chen},\n citeulike-article-id = {1371245},\n doi = {10.1002/asi.20341},\n journal = {Journal of the American Society for Information Science and Technology},\n keyword = {automatic\\_metadata\\_generation, machine\\_learning},\n link = {http://dx.doi.org/10.1002/asi.20341},\n number = {6},\n pages = {740--752},\n posted-at = {2009-06-30 07:11:32},\n priority = {2},\n title = {Finding nuggets in documents: A machine learning approach},\n volume = {57},\n year = {2006}\n}\n\n@inproceedings{ citeulike:1372858,\n abstract = {The poster reports on a project in which we are investigating methods for breaking the human metadata-generation bottleneck that plagues Digital Libraries. The research question is whether metadata elements and values can be automatically generated from the content of educational resources, and correctly assigned to mathematics and science educational materials. Natural Language Processing and Machine Learning techniques were implemented to automatically assign values of the GEMgenerate metadata element set tofor learning resources provided by the Gateway for Education (GEM), a service that offers web access to a wide range of educational materials. In a user study, education professionals evaluated the metadata assigned to learning resources by either automatic tagging or manual assignment. Results show minimal difference in the eyes of the evaluators between automatically generated metadata and manually assigned metadata.},\n address = {New York, NY, USA},\n author = {Elizabeth D. Liddy and Eileen Allen and Sarah Harwell and Susan Corieri and Ozgur Yilmazel and Ercan N. Ozgencil and Anne Diekema and Nancy Mccracken and Joanne Silverstein and Stuart Sutton},\n booktitle = {SIGIR '02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval},\n citeulike-article-id = {1372858},\n doi = {10.1145/564376.564464},\n isbn = {1581135610},\n keyword = {ao, automatic\\_metadata\\_generation, evaluation},\n link = {http://dx.doi.org/10.1145/564376.564464},\n pages = {401--402},\n posted-at = {2009-06-30 16:48:50},\n priority = {2},\n publisher = {ACM Press},\n title = {Automatic metadata generation \\& evaluation}\n}\n\n@misc{ citeulike:1377792,\n abstract = {he changing role of the user, that gradually shifts from a passive consumer of information towards a pro-active user that reorganises and manipulates data, has an increasing impact on traditional information re- trieval. A multitude of practical and methodic questions rise as popular web-applications such as blogs, RSS and social bookmarking tools allow users to create and share metadata about online resources. This article tackles these issues in the particular domain of visual cultural heritage. Online image databases increasingly offer users possibilities to annotate and comment on images of interest to them. But what is the pertinence of these user contributions? How can their quality be evaluated? Con- cretely, our article starts with an introduction to the phenomenon of user- generated metadata by presenting the social tagging of cultural heritage images and the practice of publishing users comments. Secondly, a case study presents an analysis of users comments within the image database of the National Archives of the Netherlands. Based on these empirical data, conclusions and generalizations outside our specific case study are formulat},\n author = {S. {van Hooland}},\n citeulike-article-id = {1377792},\n citeulike-linkout-0 = {http://homepages.ulb.ac.be/~svhoolan/usergeneratedmetadata.pdf},\n link = {http://homepages.ulb.ac.be/~svhoolan/usergeneratedmetadata.pdf},\n posted-at = {2010-01-16 02:37:32},\n priority = {2},\n publisher = {September},\n title = {From Spectator to Annotator: Possibilities offered by User-Generated Metadata for Digital Cultural Heritage Collections}\n}\n\n@misc{ citeulike:1453509,\n abstract = {RDF is a directed, labeled graph data format for representing information in the Web. This specification defines the syntax and semantics of the SPARQL query language for RDF. SPARQL can be used to express queries across diverse data sources, whether the data is stored natively as RDF or viewed as RDF via middleware. SPARQL contains capabilities for querying required and optional graph patterns along with their conjunctions and disjunctions. SPARQL also supports extensible value testing and constraining queries by source RDF graph. The results of SPARQL queries can be results sets or RDF graphs.},\n author = {Eric Prud'hommeaux and Andy Seaborne},\n citeulike-article-id = {1453509},\n citeulike-linkout-0 = {http://www.w3.org/TR/rdf-sparql-query/},\n howpublished = {W3C Recommendation},\n institution = {World Wide Web Consortium},\n link = {http://www.w3.org/TR/rdf-sparql-query/},\n month = {January},\n posted-at = {2010-01-15 14:21:27},\n priority = {0},\n title = {SPARQL Query Language for RDF}\n}\n\n@techreport{ citeulike:1556975,\n abstract = {This is a specification of a precise semantics, and corresponding complete systems of inference rules, for the Resource Description Framework (RDF) and RDF Schema (RDFS).},\n citeulike-article-id = {1556975},\n citeulike-linkout-0 = {http://www.w3.org/TR/rdf-mt/},\n day = {10},\n editor = {Patrick Hayes},\n howpublished = {http://www.w3.org/TR/rdf-mt/},\n institution = {W3C},\n keyword = {rdf, semantic},\n link = {http://www.w3.org/TR/rdf-mt/},\n month = {February},\n posted-at = {2010-01-15 19:43:02},\n priority = {2},\n publisher = {World Wide Web Consortium},\n series = {W3C Recommendation},\n title = {RDF Semantics}\n}\n\n@article{ citeulike:1645552,\n abstract = {Metadata enables users to find the resources they require, therefore it is an important component of any digital learning object repository. Much work has already been done within the learning technology community to assure metadata quality, focused on the development of metadata standards, specifications and vocabularies and their implementation within repositories. The metadata creation process has thus far been largely overlooked. There has been an assumption that metadata creation will be straightforward and that where machines cannot generate metadata effectively, authors of learning materials will be the most appropriate metadata creators. However, repositories are reporting difficulties in obtaining good quality metadata from their contributors, and it is becoming apparent that the issue of metadata creation warrants attention. This paper surveys the growing body of evidence, including three UK-based case studies, scopes the issues surrounding human-generated metadata creation and identifies questions for further investigation. Collaborative creation of metadata by resource authors and metadata specialists, and the design of tools and processes, are emerging as key areas for deeper research. Research is also needed into how end users will search learning object repositories.},\n author = {Sarah Currier and Jane Barton and R\\&oacute;n\\&aacute;n O\\&rsquo;beirne and Ben Ryan},\n citeulike-article-id = {1645552},\n doi = {10.1080/0968776042000211494},\n journal = {ALT-J},\n keyword = {metadata, metadata\\_creation, metadata\\_quality},\n link = {http://dx.doi.org/10.1080/0968776042000211494},\n number = {1},\n pages = {5--20},\n posted-at = {2009-07-01 21:01:35},\n priority = {0},\n publisher = {Routledge},\n title = {Quality assurance for digital learning object repositories: issues for the metadata creation process},\n volume = {12},\n year = {2004}\n}\n\n@article{ citeulike:1658742,\n address = {Tarrytown, NY, USA},\n author = {Muriel Foulonneau},\n citeulike-article-id = {1658742},\n doi = {10.1016/j.ipm.2006.06.004},\n issn = {0306-4573},\n journal = {Inf. Process. Manage.},\n keyword = {metadata, redundancy},\n link = {http://dx.doi.org/10.1016/j.ipm.2006.06.004},\n month = {May},\n number = {3},\n pages = {740--751},\n posted-at = {2009-06-30 06:04:55},\n priority = {2},\n publisher = {Pergamon Press, Inc.},\n title = {Information redundancy across metadata collections},\n volume = {43},\n year = {2007}\n}\n\n@article{ citeulike:1725563,\n abstract = {In this article, we elaborate on the meaning of quality in digital libraries (DLs) by proposing a model that is deeply grounded in a formal framework for digital libraries: 5S (Streams, Structures, Spaces, Scenarios, and Societies). For each major DL concept in the framework we formally define a number of dimensions of quality and propose a set of numerical indicators for those quality dimensions. In particular, we consider key concepts of a minimal DL: catalog, collection, digital object, metadata specification, repository, and services. Regarding quality dimensions, we consider: accessibility, accuracy, completeness, composability, conformance, consistency, effectiveness, efficiency, extensibility, pertinence, preservability, relevance, reliability, reusability, significance, similarity, and timeliness. Regarding measurement, we consider characteristics like: response time (with regard to efficiency), cost of migration (with respect to preservability), and number of service failures (to assess reliability). For some key DL concepts, the (quality dimension, numerical indicator) pairs are illustrated through their application to a number of ” real-world” digital libraries. We also discuss connections between the proposed dimensions of DL quality and an expanded version of a workshop's consensus view of the life cycle of information in digital libraries. Such connections can be used to determine when and where quality issues can be measured, assessed, and improved -- as well as how possible quality problems can be prevented, detected, and eliminated.},\n address = {Tarrytown, NY, USA},\n author = {M. Goncalves and B. Moreira and E. Fox and L. Watson},\n citeulike-article-id = {1725563},\n citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1241319},\n citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.ipm.2006.11.010},\n citeulike-linkout-2 = {http://linkinghub.elsevier.com/retrieve/pii/S030645730600197X},\n doi = {10.1016/j.ipm.2006.11.010},\n issn = {03064573},\n journal = {Information Processing \\& Management},\n keyword = {assessment, digital\\_library},\n link = {http://dx.doi.org/10.1016/j.ipm.2006.11.010},\n month = {September},\n number = {5},\n pages = {1416--1437},\n posted-at = {2010-01-15 14:01:21},\n priority = {2},\n publisher = {Pergamon Press, Inc.},\n title = {” What is a good digital library?” -- A quality model for digital libraries},\n volume = {43}\n}\n\n@article{ citeulike:1727830,\n address = {New York, NY, USA},\n author = {Tianhao Wu and William M. Pottenger},\n citeulike-article-id = {1727830},\n doi = {10.1002/asi.v56:3},\n issn = {1532-2882},\n journal = {J. Am. Soc. Inf. Sci. Technol.},\n keyword = {extraction, metadata},\n link = {http://dx.doi.org/10.1002/asi.v56:3},\n month = {February},\n number = {3},\n pages = {258--271},\n posted-at = {2009-06-30 06:42:33},\n priority = {2},\n publisher = {John Wiley \\& Sons, Inc.},\n title = {A semi-supervised active learning algorithm for information extraction from textual data: Research Articles},\n volume = {56},\n year = {2005}\n}\n\n@article{ citeulike:1810860,\n author = {Tim Berners-Lee and Nigel Shadbolt and Wendy Hall},\n citeulike-article-id = {1810860},\n citeulike-linkout-0 = {http://eprints.ecs.soton.ac.uk/12614/01/Semantic\\\\_Web\\\\_Revisted.pdf},\n journal = {IEEE Intelligent Systems},\n keyword = {semantic\\_web},\n link = {http://eprints.ecs.soton.ac.uk/12614/01/Semantic_Web_Revisted.pdf},\n month = {May},\n pages = {96--101},\n posted-at = {2010-01-16 02:06:30},\n priority = {2},\n title = {The Semantic Web Revisited},\n volume = {21.3}\n}\n\n@book{ citeulike:1940300,\n abstract = {<P>Interested in how an efficient search engine works? Want to know what algorithms are used to rank resulting documents in response to user requests? The authors answer these and other key information retrieval design and implementation questions.</P> <P>This book is not yet another high level text. Instead, algorithms are thoroughly described, making this book ideally suited for both computer science students and practitioners who work on search-related applications. As stated in the foreword, this book provides a current, broad, and detailed overview of the field and is the only one that does so. Examples are used throughout to illustrate the algorithms.</P> <P>The authors explain how a query is ranked against a document collection using either a single or a combination of retrieval strategies, and how an assortment of utilities are integrated into the query processing scheme to improve these rankings. Methods for building and compressing text indexes, querying and retrieving documents in multiple languages, and using parallel or distributed processing to expedite the search are likewise described. </P> <P>This edition is a major expansion of the one published in 1998. Besides updating the entire book with current techniques, it includes new sections on language models, cross-language information retrieval, peer-to-peer processing, XML search, mediators, and duplicate document detection. </P>},\n author = {David A. Grossman and Ophir Frieder},\n citeulike-article-id = {1940300},\n howpublished = {Paperback},\n isbn = {1402030045},\n keyword = {information\\_retrieval},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/1402030045},\n month = {December},\n posted-at = {2009-06-30 20:19:32},\n priority = {2},\n publisher = {Springer},\n title = {Information Retrieval: Algorithms and Heuristics (The Information Retrieval Series)(2nd Edition)}\n}\n\n@book{ citeulike:209816,\n author = {Chris Hart},\n citeulike-article-id = {209816},\n citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\\&amp;path=ASIN/0761959750},\n citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\\&amp;path=ASIN/0761959750},\n citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\\&amp;path=ASIN/0761959750},\n citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0761959750},\n citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0761959750/citeulike00-21},\n citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\\&path=ASIN/0761959750},\n citeulike-linkout-6 = {http://www.worldcat.org/isbn/0761959750},\n citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0761959750},\n citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0761959750\\&index=books\\&linkCode=qs},\n citeulike-linkout-9 = {http://www.librarything.com/isbn/0761959750},\n day = {01},\n howpublished = {Paperback},\n isbn = {0761959750},\n keyword = {literature\\_review},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0761959750},\n month = {March},\n posted-at = {2009-12-22 14:24:34},\n priority = {0},\n publisher = {SAGE Publications},\n title = {Doing a Literature Review : Releasing the Social Science Research Imagination},\n year = {1999}\n}\n\n@inproceedings{ citeulike:2121847,\n abstract = {The authors present a method for comparing indexing consistency between groups of indexers based on the vector space IR model. Terms assigned by indexers are treated as vectors whose distances from a central vector may be compared. The method is outlined and demonstrated with an example.},\n author = {Dietmar Wolfram and Hope A. Olson},\n booktitle = {Canadian Association for Information Science},\n citeulike-article-id = {2121847},\n citeulike-linkout-0 = {http://www.cais-acsi.ca/proceedings/2007/wolfram\\\\_2007.pdf},\n link = {http://www.cais-acsi.ca/proceedings/2007/wolfram_2007.pdf},\n organization = {Canadian Association for Information Science},\n posted-at = {2010-01-15 14:07:48},\n priority = {2},\n title = {A Method for Comparing Large Scale Inter-Indexer Consistency Using IR Modeling}\n}\n\n@article{ citeulike:2173931,\n abstract = {Latent semantic analysis has been used for several years to improve the performance of document library searches. We show that latent semantic analysis, augmented with a Part-of-Speech Tagger, may be an effective algorithm for classifying a textual document as well. Using Brille's Part-of-Speech Tagger, we truncate the singular value decomposition used in latent semantic analysis to reduce the size of the word-frequency matrix. This method is then tested on a toy problem, and has shown to increase search accuracy. We then relate these results to natural language processing and show that latent semantic analysis can be combined with context free grammars to infer semantic meaning from natural language. English is the natural language currently being used.},\n address = {Computer Science Dept., University of Southern Mississippi, 730 East Beach Blvd, Long Beach, MS 39560},\n author = {Tom Rishel and Louise A. Perkins and Sumanth Yenduri and Farnaz Zand},\n citeulike-article-id = {2173931},\n doi = {10.1002/asi.20687},\n journal = {Journal of the American Society for Information Science and Technology},\n keyword = {latent\\_sementic},\n link = {http://dx.doi.org/10.1002/asi.20687},\n number = {14},\n pages = {2197--2204},\n posted-at = {2009-06-30 06:56:53},\n priority = {2},\n title = {Determining the context of text using augmented latent semantic indexing},\n volume = {58},\n year = {2007}\n}\n\n@article{ citeulike:2191587,\n address = {Piscataway, NJ, USA},\n author = {James Hendler},\n citeulike-article-id = {2191587},\n doi = {10.1109/5254.920597},\n issn = {1541-1672},\n journal = {IEEE Intelligent Systems},\n keyword = {agent, semantic\\_web},\n link = {http://dx.doi.org/10.1109/5254.920597},\n month = {March},\n number = {2},\n pages = {30--37},\n posted-at = {2009-06-30 15:41:58},\n priority = {2},\n publisher = {IEEE Educational Activities Department},\n title = {Agents and the Semantic Web},\n volume = {16},\n year = {2001}\n}\n\n@article{ citeulike:221379,\n abstract = {The article discusses the users' perspective of information seeking. A model of the information search process is presented derived from a series of five studies investigating common experiences of users in information seeking situations. The cognitive and affective aspects of the process of information seeking suggest a gap between the users' natural process of information use and the information system and intermediaries' traditional patterns of information provision. \\&copy; 1991 John Wiley \\&amp; Sons, Inc.},\n author = {Carol C. Kuhlthau},\n citeulike-article-id = {221379},\n citeulike-linkout-0 = {http://dx.doi.org/10.1002/(SICI)1097-4571(199106)42:5%3C361::AID-ASI6%3E3.0.CO;2-%23},\n citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/10049443/ABSTRACT},\n doi = {10.1002/(SICI)1097-4571(199106)42:5%3C361::AID-ASI6%3E3.0.CO;2-%23},\n issn = {1097-4571},\n journal = {Journal of the American Society for Information Science},\n keyword = {informationh\\_behavior, model},\n link = {http://dx.doi.org/10.1002/(SICI)1097-4571(199106)42:5%3C361::AID-ASI6%3E3.0.CO;2-%23},\n month = {January},\n number = {5},\n pages = {361--371},\n posted-at = {2009-09-17 14:36:15},\n priority = {3},\n title = {Inside the search process: Information seeking from the user's perspective},\n volume = {42},\n year = {1999}\n}\n\n@article{ citeulike:222603,\n author = {R. John Robertson},\n citeulike-article-id = {222603},\n doi = {10.1108/00242530510600543},\n issn = {0024-2535},\n journal = {Library Review},\n keyword = {metadata, metadata\\_quality},\n link = {http://dx.doi.org/10.1108/00242530510600543},\n month = {May},\n number = {5},\n pages = {295--300},\n posted-at = {2009-07-01 20:58:28},\n priority = {3},\n publisher = {Emerald Group Publishing Limited},\n title = {Metadata quality: implications for library and information science professionals},\n volume = {54},\n year = {2005}\n}\n\n@mastersthesis{ citeulike:2295482,\n abstract = {A primary motivation for the development of the Semantic Web has been the need for effective information retrieval systems which may be realised through vocabulary control and the use of structured metadata. The technological framework of the Web (URI, HTTP, XML) and of the Semantic Web (RDF, OWL, SPARQL) provides a platform upon which distributed data and metadata applications may be constructed, but does not in itself provide any direct support for information retrieval applications per se. Widely applicable Semantic Web languages that extend this basic layer and provide generic support for retrieval applications, in addition to good practice guidelines and design patterns for developing such applications, are required.The ultimate purpose of this report is to develop a formal theory of retrieval using controlled vocabularies that have a simple and intuitive structure, to provide the necessary theoretical foundations for the development of Semantic Web languages and design patterns for distributed retrieval applications. The main body of this report is devoted to the articulation of such a theory. The theory is expressed formally through the use of mathematical notation, with the intention that this level of formality will provide the bridge between informal requirements specifications and the implementation of effective retrieval applications in computer systems.Specifically, a theory is developed to describe the ways in which a structured vocabulary may be used to construct an index over a collection of objects and then used to express queries which may be evaluated against an index to obtain a set of results. This theory is extended to consider ways in which both the precision and recall of retrieval strategies may be improved, through the use of expansion and ranking techniques and through ” coordination”. The problem of translating between controlled vocabularies is also considered. The theory attempts to formalise, unify and extend the traditional wisdom of the library sciences regarding the use of thesauri, classification schemes, subject heading systems, taxonomies and other types of structured vocabulary, so that proven techniques and methodologies may be transferred to a Semantic Web context.The recently chartered W3C Semantic Web Deployment Working Group has been charged with the development of the Simple Knowledge Organisation System (SKOS) to W3C Recommendation status. SKOS is a Semantic Web language specifically intended to support information retrieval applications using controlled vocabularies that have a relatively simple structure. A formal requirements specification is the first planned deliverable in the standardisation of SKOS. An immediate goal of this report is to provide a level of abstraction that can be used to perform a comparative analysis of use cases involving information retrieval systems that operate with structured vocabularies, so that the requirements of these systems with respect to Semantic Web languages such as SKOS may be clearly determined. Also, this report suggests ways in which the theory may be mapped to concrete language constructs and representation patterns in Semantic Web languages. In so doing it is hoped that the development of SKOS and similar languages may be grounded with sufficient rigour to ensure their wide applicability and consistent use.},\n author = {Alistair Miles},\n citeulike-article-id = {2295482},\n citeulike-linkout-0 = {http://isegserv.itd.rl.ac.uk/retrieval/},\n link = {http://isegserv.itd.rl.ac.uk/retrieval/},\n posted-at = {2010-01-15 14:13:58},\n priority = {2},\n title = {Retrieval and the Semantic Web: A Theory of Retrieval Using Structured Vocabularies}\n}\n\n@article{ citeulike:2359494,\n address = {New York, NY, USA},\n author = {Besiki Stvilia and Les Gasser and Michael B. Twidale and Linda C. Smith},\n citeulike-article-id = {2359494},\n doi = {10.1002/asi.v58:12},\n issn = {1532-2882},\n journal = {J. Am. Soc. Inf. Sci. Technol.},\n keyword = {assessment, metadata\\_quality},\n link = {http://dx.doi.org/10.1002/asi.v58:12},\n month = {October},\n number = {12},\n pages = {1720--1733},\n posted-at = {2009-07-01 21:13:55},\n priority = {3},\n publisher = {John Wiley \\& Sons, Inc.},\n title = {A framework for information quality assessment},\n volume = {58},\n year = {2007}\n}\n\n@inproceedings{ citeulike:2408042,\n abstract = {Most information retrieval systems on the Internet rely primarily on similarity ranking algorithms based solely on term frequency statistics. Information quality is usually ignored. This leads to the problem that documents are retrieved without regard to their quality. We present an approach that combines similarity-based similarity ranking with quality ranking in centralized and distributed search environments. Six quality metrics, including the currency, availability, information-to-noise...},\n author = {Xiaolan Zhu and Susan Gauch},\n booktitle = {Research and Development in Information Retrieval},\n citeulike-article-id = {2408042},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.40.1164},\n keyword = {misc},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.40.1164},\n pages = {288--295},\n posted-at = {2008-02-21 15:54:42},\n priority = {0},\n title = {Incorporating quality metrics in centralized/distributed information retrieval on the World Wide Web}\n}\n\n@article{ citeulike:251579,\n abstract = {Hypothesis generation, a crucial initial step for making scientific discoveries, relies on prior knowledge, experience, and intuition. Chance connections made between seemingly distinct subareas sometimes turn out to be fruitful. The goal in text mining is to assist in this process by automatically discovering a small set of interesting hypotheses from a suitable text collection. In this report, we present open and closed text mining algorithms that are built within the discovery framework established by Swanson and Smalheiser. Our algorithms represent topics using metadata profiles. When applied to MEDLINE, these are MeSH based profiles. We present experiments that demonstrate the effectiveness of our algorithms. Specifically, our algorithms successfully generate ranked term lists where the key terms representing novel relationships between topics are ranked high.},\n author = {Padmini Srinivasan},\n citeulike-article-id = {251579},\n doi = {10.1002/asi.10389},\n issn = {1532-2890},\n journal = {Journal of the American Society for Information Science and Technology},\n keyword = {text\\_minig},\n link = {http://dx.doi.org/10.1002/asi.10389},\n month = {December},\n number = {5},\n pages = {396--413},\n posted-at = {2009-06-30 06:52:36},\n priority = {2},\n title = {Text mining: Generating hypotheses from MEDLINE},\n volume = {55},\n year = {2003}\n}\n\n@techreport{ citeulike:2567842,\n author = {T. Berners-Lee},\n citeulike-article-id = {2567842},\n citeulike-linkout-0 = {http://www.w3.org/DesignIssues/Metadata},\n howpublished = {http://www.w3.org/DesignIssues/Metadata},\n link = {http://www.w3.org/DesignIssues/Metadata},\n posted-at = {2010-01-16 01:59:55},\n priority = {2},\n title = {Metadata Architecture}\n}\n\n@article{ citeulike:2594234,\n abstract = {This article proposes a method that allows a value-based assessment of metadata quality and construction of a baseline quality model. The method is illustrated on a large-scale, aggregated collection of simple Dublin core metadata records. An analysis of the collection suggests that metadata providers and end users may have different value structures for the same metadata. To promote better use of the metadata collection, value models for metadata in the collection should be made transparent to end users and end users should be allowed to participate in content creation and quality control processes.},\n author = {Besiki Stvilia and Les Gasser},\n citeulike-article-id = {2594234},\n doi = {10.1016/j.lisr.2007.06.006},\n journal = {Library \\& Information Science Research},\n keyword = {metadata, quality},\n link = {http://dx.doi.org/10.1016/j.lisr.2007.06.006},\n month = {March},\n number = {1},\n pages = {67--74},\n posted-at = {2009-06-05 14:41:36},\n priority = {2},\n title = {Value-based metadata quality assessment},\n volume = {30},\n year = {2008}\n}\n\n@inproceedings{ citeulike:2623567,\n abstract = {This paper presents early results from our empirical studies of metadata quality in large corpuses of metadata harvested under Open Archives Initiative (OAI) protocols. Along with some discussion of why and how metadata quality is important, an approach to conceptualizing, measuring, and assessing metadata quality is presented. The approach given in this paper is based on a more general model of information quality (IQ) for many kinds of information beyond just metadata. A key feature of the general model is its ability to condition quality assessments by context of information use, such as the types of activities that use the information, and the typified norms and values of relevant information-using communities. The paper presents a number of statistical characterizations of analyzed samples of metadata from a large corpus built as part of the Institute of Museum and Library Services Digital Collections and Contents (IMLS DCC) project containing OAI-harvested metadata and links these statistical assessments to the quality measures, and interprets them. Finally the paper discusses several approaches to quality improvement for metadata based on the study findings.},\n author = {Besiki Stvilia and Les Gasser and Michael B. Twidale and Sarah L. Shreeves and Timothy W. Cole},\n booktitle = {Proceedings of ICIQ04 - 9th International Conference on Information Quality.},\n citeulike-article-id = {2623567},\n keyword = {cataloging, metadata},\n link = {https://www.ideals.uiuc.edu/handle/2142/721},\n month = {November},\n organization = {IMLS},\n pages = {111--125},\n posted-at = {2008-04-02 15:34:11},\n priority = {3},\n title = {Metadata Quality for Federated Collections},\n year = {2004}\n}\n\n@article{ citeulike:2640808,\n abstract = {Abstract\\&nbsp;\\&nbsp;Most information retrieval research focuses collecting documents that match the same set of concepts. This study considers a more advanced problem, namely how to discover knowledge not contained in a single source from combined historical facts. By using a well-designed core ontology in the cultural domain (CIDOC CRM, ISO21127), this study discusses the requirement for a robust inference platform for real-life knowledge discovery and integration over distributed sources. The methodology and design are justified in detail through functional requirements for an inference service with the capability of inferring new knowledge from combinations of facts distributed over different sources. A number of critical issues for developing such a robust inference platform are identified, namely (1) systematic accumulation of common concepts and inference rules; (2) extending the ontology with metaclasses; (3) accumulation of factual and categorical knowledge; (4) incorporation of fuzzy inference into the inference engine, and (5) improvement of performance and scalability in the inference engine.},\n author = {Chia-Hung Lin and Jen-Shin Hong and Martin Doerr},\n citeulike-article-id = {2640808},\n doi = {10.1007/s00799-008-0034-0},\n journal = {International Journal on Digital Libraries},\n keyword = {cidoc, cidoc\\_crm},\n link = {http://dx.doi.org/10.1007/s00799-008-0034-0},\n month = {April},\n number = {2},\n pages = {115--132},\n posted-at = {2009-06-30 16:08:42},\n priority = {2},\n title = {Issues in an inference platform for generating deductive knowledge: a case study in cultural heritage digital libraries using the CIDOC CRM},\n volume = {8}\n}\n\n@article{ citeulike:2641720,\n abstract = {This paper presents an outline of models of information seeking and other aspects of information behaviour, showing the relationship between communication and information behaviour in general with information seeking and information searching in information retrieval systems. It is suggested that these models address issues at various levels of information behaviour and that they can be related by envisaging a `nesting' of models. It is also suggested that, within both information seeking research and information searching research, alternative models address similar issues in related ways and that the models are complementary rather than conflicting. Finally, an alternative, problem-solving model is presented, which, it is suggested, provides a basis for relating the models in appropriate research strategies.},\n author = {T. D. Wilson},\n citeulike-article-id = {2641720},\n citeulike-linkout-0 = {http://dx.doi.org/10.1108/EUM0000000007145},\n citeulike-linkout-1 = {http://www.ingentaconnect.com/content/mcb/278/1999/00000055/00000003/art00001},\n citeulike-linkout-2 = {http://informationr.net/tdw/publ/papers/1999JDoc.html},\n doi = {10.1108/EUM0000000007145},\n issn = {0022-0418},\n journal = {Journal of Documentation},\n keyword = {information\\_behaviour},\n link = {http://dx.doi.org/10.1108/EUM0000000007145},\n pages = {249--270},\n posted-at = {2009-09-15 23:34:24},\n priority = {3},\n publisher = {Emerald Group Publishing Limited},\n title = {Models in information behaviour research},\n year = {1999}\n}\n\n@book{ citeulike:2709781,\n abstract = {Introduction to Information Retrieval is the first textbook with a coherent treatment of classical and web information retrieval, including web search and the related areas of text classification and text clustering. Written from a computer science perspective, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. Designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also interest researchers and professionals. A complete set of lecture slides and exercises that accompany the book are available on the web.},\n author = {Christopher D. Manning and Prabhakar Raghavan and Hinrich Sch{\\\"u}tze},\n citeulike-article-id = {2709781},\n howpublished = {Hardcover},\n isbn = {0521865719},\n keyword = {information\\_retrieval},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0521865719},\n month = {July},\n posted-at = {2009-06-30 20:16:39},\n priority = {2},\n publisher = {Cambridge University Press},\n title = {Introduction to Information Retrieval}\n}\n\n@book{ citeulike:273980,\n abstract = {The development of the Semantic Web, with machine-readable content, has the potential to revolutionize the World Wide Web and its use. <i>A Semantic Web Primer</i> provides an introduction and guide to this emerging field, describing its key ideas, languages, and technologies. Suitable for use as a textbook or for self-study by professionals, it concentrates on undergraduate-level fundamental concepts and techniques that will enable readers to proceed with building applications on their own. It includes exercises, project descriptions, and annotated references to relevant online materials. A Semantic Web Primer is the only available book on the Semantic Web to include a systematic treatment of the different languages (XML, RDF, OWL, and rules) and technologies (explicit metadata, ontologies, and logic and inference) that are central to Semantic Web development. The book also examines such crucial related topics as ontology engineering and application scenarios.<br /> <br /> After an introductory chapter, topics covered in succeeding chapters include XML and related technologies that support semantic interoperability; RDF and RDF Schema, the standard data model for machine-processable semantics; and OWL, the W3C-approved standard for a Web ontology language more extensive than RDF Schema; rules, both monotonic and nonmonotonic, in the framework of the Semantic Web; selected application domains and how the Semantic Web would benefit them; the development of ontology-based systems; and current debates on key issues and predictions for the future.},\n author = {Grigoris Antoniou and Frank {van Harmelen}},\n citeulike-article-id = {273980},\n howpublished = {Hardcover},\n isbn = {0262012103},\n keyword = {semantic\\_web},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0262012103},\n month = {April},\n posted-at = {2009-06-30 19:51:07},\n priority = {2},\n publisher = {The MIT Press},\n title = {A Semantic Web Primer (Cooperative Information Systems)}\n}\n\n@article{ citeulike:2793160,\n abstract = {Abstract\\&nbsp;\\&nbsp;Digital libraries (DLs) have eluded definitional consensus and lack agreement on common theories and frameworks. This makes comparison of DLs extremely difficult, promotes ad-hoc development, and impedes interoperability. In this paper we propose a formal ontology for DLs that defines the fundamental concepts, relationships, and axiomatic rules that govern the DL domain, therefore providing a frame of reference for the discussion of essential concepts of DL design and construction. The ontology is an axiomatic, formal treatment of DLs, which distinguishes it from other approaches that informally define a number of architectural variants. The process of construction of the ontology was guided by 5S, a formal framework for digital libraries. To test its expressibility we have used the ontology to create a taxonomy of DL services and to reason about issues of reusability, extensibility, and composability. Some practical applications of the ontology are also described including: the definition of a digital library services taxonomy, the proposal of a modeling language for digital libraries, and the specification of quality metrics to evaluate digital libraries. We also demonstrate how to use the ontology to formally describe DL architectures and to prove some properties about them, thus helping to further validate the ontology.},\n author = {Marcos Gon\\c{c}alves and Edward Fox and Layne Watson},\n citeulike-article-id = {2793160},\n citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00799-008-0033-1},\n citeulike-linkout-1 = {http://www.ingentaconnect.com/content/klu/799/2008/00000008/00000002/00000033},\n citeulike-linkout-2 = {http://www.springerlink.com/content/f74353ph47n55234},\n day = {1},\n doi = {10.1007/s00799-008-0033-1},\n issn = {1432-5012},\n journal = {International Journal on Digital Libraries},\n link = {http://dx.doi.org/10.1007/s00799-008-0033-1},\n month = {April},\n number = {2},\n pages = {91--114},\n posted-at = {2010-01-15 20:20:39},\n priority = {2},\n publisher = {Springer},\n title = {Towards a digital library theory: a formal digital library ontology},\n volume = {8}\n}\n\n@article{ citeulike:284929,\n abstract = {This study evaluates the data sources and research methods used in earlier studies to rank the research productivity of Library and Information Science (LIS) faculty and schools. In doing so, the study identifies both tools and methods that generate more accurate publication count rankings as well as databases that should be taken into consideration when conducting comprehensive searches in the literature for research and curricular needs. With a list of 2,625 items published between 1982 and 2002 by 68 faculty members of 18 American Library Association- (ALA-) accredited LIS schools, hundreds of databases were searched. Results show that there are only 10 databases that provide significant coverage of the LIS indexed literature. Results also show that restricting the data sources to one, two, or even three databases leads to inaccurate rankings and erroneous conclusions. Because no database provides comprehensive coverage of the LIS literature, researchers must rely on a wide range of disciplinary and multidisciplinary databases for ranking and other research purposes. The study answers such questions as the following: Is the Association of Library and Information Science Education's (ALISE's) directory of members a reliable tool to identify a complete list of faculty members at LIS schools? How many and which databases are needed in a multifile search to arrive at accurate publication count rankings? What coverage will be achieved using a certain number of databases? Which research areas are well covered by which databases? What alternative methods and tools are available to supplement gaps among databases? Did coverage performance of databases change over time? What counting method should be used when determining what and how many items each LIS faculty and school has published? The authors recommend advanced analysis of research productivity to provide a more detailed assessment of research productivity of authors and programs.},\n author = {Lokman I. Meho and Kristina M. Spurgin},\n citeulike-article-id = {284929},\n doi = {10.1002/asi.20227},\n issn = {1532-2890},\n journal = {Journal of the American Society for Information Science and Technology},\n keyword = {rankding\\_lis},\n link = {http://dx.doi.org/10.1002/asi.20227},\n month = {August},\n posted-at = {2009-06-30 16:43:18},\n priority = {2},\n title = {Ranking the research productivity of library and information science faculty and schools: An evaluation of data sources and research methods},\n year = {2005}\n}\n\n@book{ citeulike:290835,\n abstract = {Knowledge representation is at the very core of a radical idea for understanding intelligence. Instead of trying to understand or build brains from the bottom up, its goal is to understand and build intelligent behavior from the top down, putting the focus on what an agent needs to know in order to behave intelligently, how this knowledge can be represented symbolically, and how automated reasoning procedures can make this knowledge available as needed. <br><br>This landmark text takes the central concepts of knowledge representation developed over the last 50 years and illustrates them in a lucid and compelling way. Each of the various styles of representation is presented in a simple and intuitive form, and the basics of reasoning with that representation are explained in detail. This approach gives readers a solid foundation for understanding the more advanced work found in the research literature. The presentation is clear enough to be accessible to a broad audience, including researchers and practitioners in database management, information retrieval, and object-oriented systems as well as artificial intelligence. This book provides the foundation in knowledge representation and reasoning that every AI practitioner needs.<br><br>*Authors are well-recognized experts in the field who have applied the techniques to real-world problems <br>* Presents the core ideas of KR\\&R in a simple straight forward approach, independent of the quirks of research systems <br>*Offers the first true synthesis of the field in over a decade},\n author = {Ronald Brachman and Hector Levesque},\n citeulike-article-id = {290835},\n howpublished = {Hardcover},\n isbn = {1558609326},\n keyword = {ai},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/1558609326},\n month = {May},\n posted-at = {2009-06-30 20:42:40},\n priority = {2},\n publisher = {Morgan Kaufmann},\n title = {Knowledge Representation and Reasoning (The Morgan Kaufmann Series in Artificial Intelligence)}\n}\n\n@inproceedings{ citeulike:2916089,\n abstract = {We describe a Web-based metadata quality tool that provides statistical descriptions and visualisations of Dublin Core metadata harvested via the OAI protocol. The lightweight nature of development allows it to be used to gather contextualized requirements and some initial user feedback is discussed.},\n address = {New York, NY, USA},\n author = {David M. Nichols and Chu-Hsiang Chan and David Bainbridge and Dana Mckay and Michael B. Twidale},\n booktitle = {JCDL '08: Proceedings of the 8th ACM/IEEE-CS joint conference on Digital libraries},\n citeulike-article-id = {2916089},\n doi = {10.1145/1378889.1378957},\n isbn = {9781595939982},\n keyword = {metadata, metadata\\_quality},\n link = {http://dx.doi.org/10.1145/1378889.1378957},\n pages = {385--388},\n posted-at = {2009-06-30 12:31:03},\n priority = {2},\n publisher = {ACM},\n title = {A lightweight metadata quality tool},\n year = {2008}\n}\n\n@article{ citeulike:2968181,\n abstract = {Biomedical literature databases constitute valuable repositories of up to date scientific knowledge. The development of efficient machine learning methods in order to facilitate the organization of these databases and the extraction of novel biomedical knowledge is becoming increasingly important. Several of these methods require the representation of the documents as vectors of variables forming large multivariate datasets. Since the amount of information contained in different datasets is voluminous, an open issue is to combine information gained from various sources to a concise new dataset, which will efficiently represent the corpus of documents. This paper investigates the use of the multivariate statistical approach, called Non-Linear Canonical Correlation Analysis (NLCCA), for exploiting the correlation among the variables of different document representations and describing the documents with only one new dataset. Experiments with document datasets represented by text words, Medical Subject Headings (MeSH) and Gene Ontology (GO) terms showed the effectiveness of NLCCA.},\n address = {Department of Informatics, School of Natural Sciences, Aristotle University of Thessaloniki, 54124 Thessaloniki, Greece. theodos@csd.auth.gr},\n author = {T. Theodosiou and L. Angelis and A. Vakali},\n citeulike-article-id = {2968181},\n doi = {10.1016/j.jbi.2007.06.004},\n issn = {1532-0480},\n journal = {Journal of biomedical informatics},\n keyword = {extraction, metadata},\n link = {http://dx.doi.org/10.1016/j.jbi.2007.06.004},\n month = {February},\n number = {1},\n pages = {202--216},\n posted-at = {2009-06-30 11:57:17},\n priority = {2},\n title = {Non-linear correlation of content and metadata information extracted from biomedical article datasets.},\n volume = {41},\n year = {2008}\n}\n\n@misc{ citeulike:2968250,\n abstract = {In spite of its tremendous value, metadata is generally sparse and incomplete, thereby hampering the effectiveness of digital information services. Many of the existing mechanisms for the automated creation of metadata rely primarily on content analysis which can be costly and inefficient. The automatic metadata generation system proposed in this article leverages resource relationships generated from existing metadata as a medium for propagation from metadata-rich to metadata-poor resources. Because of its independence from content analysis, it can be applied to a wide variety of resource media types and is shown to be computationally inexpensive. The proposed method operates through two distinct phases. Occurrence and co-occurrence algorithms first generate an associative network of repository resources leveraging existing repository metadata. Second, using the associative network as a substrate, metadata associated with metadata-rich resources is propagated to metadata-poor resources by means of a discrete-form spreading activation algorithm. This article discusses the general framework for building associative networks, an algorithm for disseminating metadata through such networks, and the results of an experiment and validation of the proposed method using a standard bibliographic dataset.},\n archiveprefix = {arXiv},\n author = {Marko A. Rodriguez and Johan Bollen and Herbert {Van de Sompel}},\n citeulike-article-id = {2968250},\n eprint = {0807.0023},\n keyword = {generation, metadata},\n link = {http://arxiv.org/abs/0807.0023},\n month = {Jun},\n posted-at = {2009-06-30 06:18:58},\n priority = {2},\n title = {Automatic Metadata Generation using Associative Networks},\n year = {2008}\n}\n\n@book{ citeulike:3090157,\n author = {Franz Baader and Diego Calvanese and Deborah L. Mcguinness and Daniele Nardi and Peter F. Patel-Schneider},\n citeulike-article-id = {3090157},\n edition = {Second},\n keyword = {description\\_logic},\n posted-at = {2009-06-30 20:36:54},\n priority = {2},\n publisher = {Cambridge University Press},\n title = {The Description Logic Handbook}\n}\n\n@article{ citeulike:328465,\n author = {Latifur Khan and Dennis Mcleod and Eduard Hovy},\n citeulike-article-id = {328465},\n doi = {10.1007/s10844-005-0188-9},\n issn = {0925-9902},\n journal = {Journal of Intelligent Information Systems},\n keyword = {ontology},\n link = {http://dx.doi.org/10.1007/s10844-005-0188-9},\n month = {September},\n number = {2},\n pages = {181--205},\n posted-at = {2009-06-30 11:50:38},\n priority = {2},\n publisher = {Kluwer Academic Publishers},\n title = {A Framework for Effective Annotation of Information from Closed Captions Using Ontologies},\n volume = {25},\n year = {2005}\n}\n\n@techreport{ citeulike:3470246,\n abstract = {Current institutional repository software provides few tools to help metadata librarians understand and analyse their collections. In this paper we compare and contrast metadata analysis tools that were developed simultaneously, but independently, at two New Zealand institutions during a period of national investment in research repositories: the Metadata Analysis Tool (MAT) at The University of Waikato, and the Kiwi Research Information Service (KRIS) at the National Library of New Zealand. The tools have many similarities: they are convenient, online, on-demand services that harvest metadata using OAI-PMH, they were developed in response to feedback from repository administrators, and they both help pinpoint specific metadata errors as well as generating summary statistics. They also have significant differences: one is a dedicated tool while the other is part of a wider access tool; one gives a holistic view of the metadata while the other looks for specific problems; one seeks patterns in the data values while the other checks that those values conform to metadata standards. Both tools work in a complementary manner to existing web-based administration tools. We have observed that discovery and correction of metadata errors can be quickly achieved by switching web browser views from the analysis tool to the repository interface, and back. We summarise the findings from both tools' deployment into a checklist of requirements for metadata analysis tools.},\n author = {David M. Nichols and Gordon W. Paynter and Chu-Hsiang Chan and David Bainbridge and Dana Mckay and Michael B. Twidale and Ann Blandford},\n citeulike-article-id = {3470246},\n keyword = {metadata},\n link = {http://eprints.rclis.org/archive/00014732/},\n month = {August},\n organization = {Department of Computer Science-University of Waikato Working Paper Series},\n posted-at = {2009-06-30 12:33:16},\n priority = {2},\n title = {Metadata tools for institutional repositories},\n year = {2008}\n}\n\n@article{ citeulike:3613626,\n abstract = {Abstract\\&nbsp;\\&nbsp;Many scholarly writings today are available in electronic formats. With universities around the world choosing to make digital versions of their dissertations, theses, project reports, and related files and data sets available online, an overwhelming amount of information is becoming available on almost any particular topic. How will users decide which dissertation, or subsection of a dissertation, to read to get the required information on a particular topic? What kind of services can such digital libraries provide to make knowledge discovery easier? In this paper, we investigate these issues, using as a case study the Networked Digital Library of Theses and Dissertations (NDLTD), a rapidly growing collection that already has about 800,000 Electronic Theses and Dissertations (ETDs) from universities around the world. We propose the design for a scalable, Web Services based tool KDWebS (Knowledge Discovery System based on Web Services), to facilitate automated knowledge discovery in NDLTD. We also provide some preliminary proof of concept results to demonstrate the efficacy of the approach.},\n author = {W. Richardson and Venkat Srinivasan and Edward Fox},\n citeulike-article-id = {3613626},\n citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00799-008-0046-9},\n citeulike-linkout-1 = {http://www.springerlink.com/content/w3182840w7j17117},\n day = {1},\n doi = {10.1007/s00799-008-0046-9},\n journal = {International Journal on Digital Libraries},\n link = {http://dx.doi.org/10.1007/s00799-008-0046-9},\n month = {November},\n number = {2},\n pages = {163--171},\n posted-at = {2010-01-15 20:50:28},\n priority = {2},\n title = {Knowledge discovery in digital libraries of electronic theses and dissertations: an NDLTD case study},\n volume = {9}\n}\n\n@misc{ citeulike:379834,\n abstract = {The growing infrastructure for Web Services assumes a \\&quot;programmer in the loop\\&quot; that hardcodes the connections between Web Services and directly programs Web Service composition. Emerging technology based on DAML-S and the Semantic Web allows Web Services to connect and transact automatically with minimal or no intervention from programmers. In this paper we discuss the problems related with autonomous Web Services, and how DAMLS provides the information to solve them. Furthermore, we describe...},\n author = {M. Paolucci and K. Sycara and T. Kawamura},\n citeulike-article-id = {379834},\n keyword = {semantic\\_web, web\\_services},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.4382},\n posted-at = {2009-06-30 16:19:43},\n priority = {2},\n title = {Delivering Semantic Web Services},\n year = {2002}\n}\n\n@book{ citeulike:3816245,\n address = {88 Post Road West, Westport, CT 06881},\n author = {Sheila S. Intner and Susan I. Lazinger and Jean Weihs},\n citeulike-article-id = {3816245},\n citeulike-linkout-0 = {http://www.webology.ir/2006/v3n3/bookreview5.html},\n isbn = {1591581451},\n keyword = {metadata},\n link = {http://www.webology.ir/2006/v3n3/bookreview5.html},\n posted-at = {2009-12-20 14:41:59},\n priority = {0},\n publisher = {Libraries Unlimited},\n title = {Metadata and Its Impact on Libraries}\n}\n\n@inproceedings{ citeulike:3833131,\n address = {New York, NY, USA},\n author = {Steffen Oldenburg and Martin Garbe and Clemens Cap},\n booktitle = {SSM '08: Proceeding of the 2008 ACM workshop on Search in social media},\n citeulike-article-id = {3833131},\n doi = {10.1145/1458583.1458587},\n isbn = {9781605582580},\n keyword = {similarity\\_analysis, social\\_classification},\n link = {http://dx.doi.org/10.1145/1458583.1458587},\n location = {Napa Valley, California, USA},\n pages = {11--18},\n posted-at = {2009-06-30 15:58:50},\n priority = {2},\n publisher = {ACM},\n title = {Similarity cross-analysis of tag / co-tag spaces in social classification systems}\n}\n\n@article{ citeulike:3852086,\n author = {Alfred J. Lotka},\n citeulike-article-id = {3852086},\n citeulike-linkout-0 = {http://dx.doi.org/10.1002/asi.4630280610},\n doi = {10.1002/asi.4630280610},\n journal = {J Washington Acad Sci},\n keyword = {bibliometrics},\n link = {http://dx.doi.org/10.1002/asi.4630280610},\n pages = {317--324},\n posted-at = {2010-04-07 04:25:57},\n priority = {2},\n title = {The frequency distribution of scientific productivity},\n volume = {16}\n}\n\n@article{ citeulike:3857646,\n abstract = {Findings from a data mapping and extraction exercise undertaken as part of the STAR project are described and related to recent work in the area. The exercise was undertaken in conjunction with English Heritage and encompassed five differently structured relational databases containing various results of archaeological excavations. The aim of the exercise was to demonstrate the potential benefits in cross searching data expressed as RDF and conforming to a common overarching conceptual data structure schema - the English Heritage Centre for Archaeology ontological model (CRM-EH), an extension of the CIDOC Conceptual Reference Model (CRM). A semi-automatic mapping/extraction tool proved an essential component. The viability of the approach is demonstrated by web services and a client application on an integrated data and concept network.},\n author = {Ceri Binding and Keith May and Douglas Tudhope},\n citeulike-article-id = {3857646},\n doi = {10.1007/978-3-540-87599-4\\_30},\n journal = {Research and Advanced Technology for Digital Libraries},\n keyword = {cidoc\\_crm, semantic\\_interoperability},\n link = {http://dx.doi.org/10.1007/978-3-540-87599-4_30},\n pages = {280--290},\n posted-at = {2009-06-30 16:14:44},\n priority = {2},\n title = {Semantic Interoperability in Archaeological Datasets: Data Mapping and Extraction Via the CIDOC CRM}\n}\n\n@article{ citeulike:3861763,\n abstract = {A study to develop a methodology for studying index consistency in machine readable cataloging (MARC) records and to study such consistency in subject cataloging practice between the Library of Congress (LC) and non-LC libraries found that consistency among indexers is difficult to achieve even when the same indexing policies and vocabulary are used.},\n author = {Lois M. Chan},\n citeulike-article-id = {3861763},\n citeulike-linkout-0 = {http://proquest.umi.com/pqdweb?did=7096175\\&\\\\#38;Fmt=7\\&\\\\#38;clientId=11263\\&\\\\#38;RQT=309\\&\\\\#38;VName=PQD},\n journal = {Information Technology and Libraries},\n keyword = {interindexer\\_consistency, metadata, subject\\_analysis},\n link = {http://proquest.umi.com/pqdweb?did=7096175&#38;Fmt=7&#38;clientId=11263&#38;RQT=309&#38;VName=PQD},\n number = {4},\n pages = {349--358},\n posted-at = {2010-03-14 00:05:03},\n priority = {3},\n title = {Inter-Indexer Consistency in Subject Cataloging},\n volume = {8}\n}\n\n@article{ citeulike:3861772,\n abstract = {It is often assumed that the amount of interindexer consistency experienced under a given method of indexing is somehow indicative of the quality of the indexing. To explore this assumption, two hypotheses are stated concerning the possible connection between interindexer consistency and indexing quality. A specific counter-example is then exhibited which shows both hypotheses to be invalid. Although a mathematical analysis of the counterexample yields certain insights, the general relationship between interindexer consistency and successful retrieval is more subtle than might have been expected. It is concluded that until equations describing this relationship have been derived, measurements of interindexer consistency will have little meaning as clues to indexing quality.},\n author = {William S. Cooper},\n citeulike-article-id = {3861772},\n citeulike-linkout-0 = {http://dx.doi.org/10.1002/asi.4630200314},\n doi = {10.1002/asi.4630200314},\n journal = {American Documentation},\n keyword = {interindexer\\_consistency},\n link = {http://dx.doi.org/10.1002/asi.4630200314},\n number = {3},\n pages = {268--278},\n posted-at = {2010-01-15 19:55:29},\n priority = {0},\n title = {Is interindexer consistency a hobgoblin?},\n volume = {20}\n}\n\n@misc{ citeulike:3861904,\n author = {Tony Gill},\n citeulike-article-id = {3861904},\n citeulike-linkout-0 = {http://www.firstmonday.org/issues/issue9\\\\_5/gill/},\n howpublished = {http://www.firstmonday.org/issues/issue9\\\\\\_5/gill/},\n keyword = {cidoc},\n link = {http://www.firstmonday.org/issues/issue9_5/gill/},\n month = {May},\n posted-at = {2010-01-15 02:52:17},\n priority = {0},\n title = {Building semantic bridges between museums, libraries and archives},\n year = {2004}\n}\n\n@article{ citeulike:3906895,\n abstract = {The authors demonstrate how to use Semantic Web technologies to improve the state-of-the-art in online learning environments and bridge the gap between students on the one hand, and authors or teachers on the other. The ontological framework presented here helps formalize learning object context as a complex interplay of different learning-related elements and shows how we can use semantic annotation to interrelate diverse learning artifacts. On top of this framework, the authors implemented several feedback channels for educators to improve the delivery of future Web-based courses.},\n address = {Los Alamitos, CA, USA},\n author = {Jelena Jovanovi\\&\\#263; and Dragan Ga\\&\\#353;evi\\&\\#263; and Christopher Brooks and Vladan Deved\\&\\#382;i\\&\\#263; and Marek Hatala and Timmy Eap and Griff Richards},\n citeulike-article-id = {3906895},\n doi = {10.1109/MIC.2007.116},\n issn = {1089-7801},\n journal = {IEEE Internet Computing},\n keyword = {learning\\_content, semantic\\_web},\n link = {http://dx.doi.org/10.1109/MIC.2007.116},\n number = {5},\n pages = {45--53},\n posted-at = {2009-06-30 07:19:55},\n priority = {2},\n publisher = {IEEE Computer Society},\n title = {Using Semantic Web Technologies to Analyze Learning Content},\n volume = {11},\n year = {2007}\n}\n\n@article{ citeulike:4008885,\n author = {T. D. Wilson},\n citeulike-article-id = {4008885},\n citeulike-linkout-0 = {http://dx.doi.org/10.1108/00220410610714895},\n doi = {10.1108/00220410610714895},\n journal = {Journal of Documentation},\n keyword = {informationh\\_behavior},\n link = {http://dx.doi.org/10.1108/00220410610714895},\n number = {6},\n pages = {658--670},\n posted-at = {2009-09-15 23:41:53},\n priority = {3},\n title = {On user studies and information needs},\n volume = {62},\n year = {2006}\n}\n\n@article{ citeulike:4052132,\n abstract = {This research explores the capabilities of two Dublin Core automatic metadata generation applications, Klarity and DC-dot. The top level Web page for each resource, from a sample of 29 resources obtained from National Institute of Environmental Health Sciences (NIEHS), was submitted to both generators. Results indicate that extraction processing algorithms can contribute to useful automatic metadata generation. Results also indicate that harvesting metadata from META tags created by humans can have a positive impact on automatic metadata generation. The study identifies several ways in which automatic metadata generation applications can be improved and highlights several important areas of research. The conclusion is that integrating extraction of harvesting methods will be the best approach to creating optimal metadata, and more research is needed to identify when to apply which method.},\n author = {Jane Greenberg},\n citeulike-article-id = {4052132},\n doi = {10.1300/J141v06n04\\_05},\n journal = {Journal of Library Metadata},\n keyword = {extraction, harvest, metadata},\n link = {http://dx.doi.org/10.1300/J141v06n04\\_05},\n number = {4},\n pages = {59--82},\n posted-at = {2009-06-05 14:37:11},\n priority = {2},\n publisher = {Routledge},\n title = {Metadata Extraction and Harvesting},\n volume = {6},\n year = {2004}\n}\n\n@article{ citeulike:4052921,\n abstract = {The digital age has caused the paradigm to shift in academic libraries both in terms of their collections and the roles of their personnel. As academic libraries begin to digitize objects in their collections, how and who in the library creates access to these resources has become a hot issue. At the University of Nebraska-Lincoln Libraries (UNL Libraries), taskforces were formed to study metadata schemes used at UNL Libraries. The taskforces identified the various metadata schemes in use and the role of various departments within UNL Libraries in the creation of metadata. They made recommendations about how to document decisions relating to metadata and how to coordinate metadata creation and digitization projects. As a result, the authors decided to survey American Research Libraries (ARL) and other peer libraries to determine their metadata workflow. This paper discusses the results of the survey and provides insight as to how libraries may meet the challenge of creating metadata through the reorganization of departments and staffing responsibilities.},\n author = {Adonna Fleming and Margaret Mering and Judith A. Wolfe},\n citeulike-article-id = {4052921},\n doi = {10.1080/07317130802127983},\n journal = {Technical Services Quarterly},\n keyword = {metadata, metadata\\_creation},\n link = {http://dx.doi.org/10.1080/07317130802127983},\n number = {4},\n pages = {1--15},\n posted-at = {2009-07-01 20:54:57},\n priority = {2},\n publisher = {Routledge},\n title = {Library Personnel's Role in the Creation of Metadata: A Survey of Academic Libraries},\n volume = {25}\n}\n\n@article{ citeulike:4072081,\n abstract = {This article introduces the Simple Knowledge Organisation System (SKOS), a Semantic Web language for representing controlled structured vocabularies, including thesauri, classification schemes, subject heading systems, and taxonomies. SKOS provides a framework for publishing thesauri, classification schemes, and subject indexes on the Web, and for applying these systems to resource collections that are part of the Semantic Web. Semantic Web applications may harvest and merge SKOS data, to integrate and enhance retrieval service across multiple collections (e.g., libraries). This article also describes some alternatives for integrating Semantic Web services based on the Resource Description Framework (RDF) and SKOS into a distributed enterprise architecture.},\n author = {Alistair Miles and Jos{\\'e} R. P{\\'e}rez-Ag{\\\"u}era},\n citeulike-article-id = {4072081},\n citeulike-linkout-0 = {http://dx.doi.org/10.1300/J104v43n03\\\\_04},\n doi = {10.1300/J104v43n03\\_04},\n journal = {Cataloging \\& Classification Quarterly},\n link = {http://dx.doi.org/10.1300/J104v43n03_04},\n number = {3},\n pages = {69--83},\n posted-at = {2010-01-15 14:29:45},\n priority = {2},\n publisher = {Routledge},\n title = {SKOS: Simple Knowledge Organisation for the Web},\n volume = {43}\n}\n\n@article{ citeulike:4087393,\n abstract = {This article presents the methodology that has been successfully used over the past seven years by an interdisciplinary team to create the International Committee for Documentation of the International Council of Museums (CIDOC) CONCEPTUAL REFERENCE MODEL (CRM), a high-level ontology to enable information integration for cultural heritage data and their correlation with library and archive information. The CIDOC CRM is now in the process to become an International Organization for Standardization (ISO) standard. This article justifies in detail the methodology and design by functional requirements and gives examples of its contents. The CIDOC CRM analyzes the common conceptualizations behind data and metadata structures to support data transformation, mediation, and merging. It is argued that such ontologies are property-centric, in contrast to terminological systems, and should be built with different methodologies. It is demonstrated that ontological and epistemological arguments are equally important for an effective design, in particular when dealing with knowledge from the past in any domain. It is assumed that the presented methodology and the upper level of the ontology are applicable in a far wider domain.},\n address = {Menlo Park, CA, USA},\n author = {Martin Doerr},\n citeulike-article-id = {4087393},\n issn = {0738-4602},\n journal = {AI Mag.},\n keyword = {cidoc, cidoc\\_crm},\n link = {http://portal.acm.org/citation.cfm?id=958678},\n number = {3},\n pages = {75--92},\n posted-at = {2009-06-30 16:10:21},\n priority = {2},\n publisher = {American Association for Artificial Intelligence},\n title = {The CIDOC conceptual reference module: an ontological approach to semantic interoperability of metadata},\n volume = {24},\n year = {2003}\n}\n\n@article{ citeulike:4107599,\n abstract = {The application of thesauri in networked environments is seriously hampered by the challenges of introducing new concepts and terminology into the formal controlled vocabulary, which is critical for enhancing its retrieval capability. The author describes an automated process of adding new terms to thesauri as entry vocabulary by analyzing the association between words/phrases extracted from bibliographic titles and subject descriptors in the metadata record (subject descriptors are terms assigned from controlled vocabularies of thesauri to describe the subjects of the objects [e.g., books, articles] represented by the metadata records). The investigated approach uses a corpus of metadata for scientific and technical (S\\&T) publications in which the titles contain substantive words for key topics. The three steps of the method are (a) extracting words and phrases from the title field of the metadata; (b) applying a method to identify and select the specific and meaningful keywords based on the associated controlled vocabulary terms from the thesaurus used to catalog the objects; and (c) inserting selected keywords into the thesaurus as new terms (most of them are in hierarchical relationships with the existing concepts), thereby updating the thesaurus with new terminology that is being used in the literature. The effectiveness of the method was demonstrated by an experiment with the Chinese Classification Thesaurus (CCT) and bibliographic data in China Machine-Readable Cataloging Record (MARC) format (CNMARC) provided by Peking University Library. This approach is equally effective in large-scale collections and in other languages.},\n address = {Department of Information Management, Peking University, Beijing 10071, China},\n author = {Jun Wang},\n citeulike-article-id = {4107599},\n doi = {10.1002/asi.20352},\n journal = {Journal of the American Society for Information Science and Technology},\n keyword = {extraction, metadata, thesaurus},\n link = {http://dx.doi.org/10.1002/asi.20352},\n number = {7},\n pages = {907--920},\n posted-at = {2009-06-30 16:45:53},\n priority = {2},\n title = {Automatic thesaurus development: Term extraction from title metadata},\n volume = {57},\n year = {2006}\n}\n\n@inproceedings{ citeulike:4109359,\n abstract = {The CORES metadata schemas registry is designed to enable users to discover and navigate metadata element sets. The paper reflects on some of the experiences of implementing the registry, and examines some of the issues of promoting such services in the context of a \"partially Semantic Web\" where metadata applications are evolving and many have not yet adopted the RDF model.},\n author = {Rachel Heery and Pete Johnston and Csaba F{\\\"u}l{\\\"o}p and Andr{\\'a}s Micsik},\n booktitle = {DCMI '03: Proceedings of the 2003 international conference on Dublin Core and metadata applications},\n citeulike-article-id = {4109359},\n isbn = {0974530301},\n keyword = {cores, metadata, registry, semantic, web},\n link = {http://portal.acm.org/citation.cfm?id=1383296.1383299},\n location = {Seattle, Washington},\n pages = {1--8},\n posted-at = {2009-06-05 14:39:45},\n priority = {2},\n publisher = {Dublin Core Metadata Initiative},\n title = {Metadata schema registries in the partially Semantic web: the CORES experience}\n}\n\n@article{ citeulike:4149292,\n abstract = {Key words: scholarly discourse -- scientific publishing --ontologies -- knowledge-based systems -- argumentation -- visualization -- eprint servers -- internet digital libraries Abstract. The internet is rapidly becoming the first place for researchers to publish documents, but at present they receive little support in searching, tracking, analyzing or debating concepts in a literature from scholarly perspectives. This paper describes the design rationale and implementation of ScholOnto, an ontology-based digital library server to support scholarly interpretation and discourse. It enables researchers to describe and debate via a semantic network the contributions a document makes, and its relationship to the literature. The paper discusses the computational services that an ontology-based server supports, alternative user interfaces to support interaction with a large semantic network, usability issues associated with knowledge formalization, new work practices that could emerge, and related work. 1 1},\n author = {Simon B. Shum and Enrico Motta and John Domingue},\n citeulike-article-id = {4149292},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.3835},\n journal = {International Journal on Digital Libraries},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.3835},\n pages = {237--248},\n posted-at = {2010-01-15 14:23:09},\n priority = {2},\n title = {ScholOnto: an Ontology-Based Digital Library Server for Research Documents and Discourse},\n volume = {3}\n}\n\n@article{ citeulike:4149298,\n abstract = {In the age of digital information more and more digital libraries and historical archives are using information systems in order to facilitate the document retrieval and provide better visualization of the search results and document presentation. Much research has been done in the field of digital libraries, but in the case of historical archives, which have particular needs, this is not the case. To this end, we investigate the use of new tools, which are based on the ontology of the historical archive in order to provide a new and effective method for document retrieval in a dynamic environment which will take into account the collaboration needs of the users.},\n author = {Katifori Akrivi and Golemati Maria},\n citeulike-article-id = {4149298},\n keyword = {library, ontology},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.130.6092},\n posted-at = {2009-03-08 16:44:53},\n priority = {2},\n title = {Ontology Aided Information Retrieval in Digital Historical Archives}\n}\n\n@article{ citeulike:4149301,\n abstract = {In this paper, we argue that a core ontology is one of the key building blocks necessary to enable the scalable assimilation of information from diverse sources. A complete and extensible ontology that expresses the basic concepts that are common across a variety of domains and can provide the basis for specialization into domain-specific concepts and vocabularies, is essential for well-defined mappings between domain-specific knowledge representations (i.e., metadata vocabularies) and the subsequent building of a variety of services such as cross-domain searching, browsing, data mining and knowledge extraction. This paper describes the results of a series of three workshops held in 2001 and 2002 which brought together representatives from the cultural heritage and digital library communities with the goal of harmonizing their knowledge perspectives and producing a core ontology. The knowledge perspectives of these two communities were represented by the CIDOC/CRM [31], an ontology for information exchange in the cultural heritage and museum community, and the ABC ontology [33], a model for the exchange and integration of digital library information. This paper describes the mediation process between these two different knowledge biases and the results of this mediation -- the harmonization of the ABC and CIDOC/CRM ontologies, which we believe may provide a useful basis for information integration in the wider scope of the involved communities.},\n author = {Martin Doerr and Jane Hunter and Carl Lagoze},\n citeulike-article-id = {4149301},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.6.409},\n citeulike-linkout-1 = {http://journals.tdl.org/jodi/article/download/92/91},\n journal = {Journal of Digital Information},\n keyword = {cidoc\\_crm, ontology},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.6.409},\n number = {1},\n posted-at = {2009-06-30 16:12:43},\n priority = {2},\n title = {Towards a core ontology for information integration},\n volume = {4}\n}\n\n@article{ citeulike:4162566,\n author = {Qing Zou and Guoying Liu},\n citeulike-article-id = {4162566},\n doi = {10.1108/00330330910934101},\n issn = {0033-0337},\n journal = {Program: electronic library \\& information systems},\n link = {http://dx.doi.org/10.1108/00330330910934101},\n number = {1},\n pages = {49--61},\n posted-at = {2009-03-10 18:57:46},\n publisher = {Emerald Group Publishing Limited},\n title = {Chinese localisation of Evergreen: an open source integrated library system},\n volume = {43},\n year = {2009}\n}\n\n@article{ citeulike:4199625,\n abstract = {Current data integration approaches by bioinformaticians frequently involve extracting data from a wide variety of public and private data repositories, each with a unique vocabulary and schema, via scripts. These separate data sets must then be normalized through the tedious and lengthy process of resolving naming differences and collecting information into a single view. Attempts to consolidate such diverse data using data warehouses or federated queries add significant complexity and have shown limitations in flexibility. The alternative of complete semantic integration of data requires a massive, sustained effort in mapping data types and maintaining ontologies. We focused instead on creating a data architecture that leverages semantic mapping of experimental metadata, to support the rapid prototyping of scientific discovery applications with the twin goals of reducing architectural complexity while still leveraging semantic technologies to provide flexibility, efficiency and more fully characterized data relationships. A metadata ontology was developed to describe our discovery process. A metadata repository was then created by mapping metadata from existing data sources into this ontology, generating RDF triples to describe the entities. Finally an interface to the repository was designed which provided not only search and browse capabilities but complex query templates that aggregate data from both RDF and RDBMS sources. We describe how this approach (i) allows scientists to discover and link relevant data across diverse data sources and (ii) provides a platform for development of integrative informatics applications. 10.1093/bib/bbp007},\n author = {Maurice Manning and Amit Aggarwal and Kevin Gao and Greg Tucker-Kellogg},\n citeulike-article-id = {4199625},\n citeulike-linkout-0 = {http://dx.doi.org/10.1093/bib/bbp007},\n citeulike-linkout-1 = {http://bib.oxfordjournals.org/cgi/content/abstract/10/2/164?etoc},\n citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19304872},\n citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19304872},\n day = {1},\n doi = {10.1093/bib/bbp007},\n issn = {1477-4054},\n journal = {Brief Bioinform},\n keyword = {metadata\\_semantics, semantic\\_integration},\n link = {http://dx.doi.org/10.1093/bib/bbp007},\n month = {March},\n number = {2},\n pages = {164--176},\n posted-at = {2010-01-25 18:46:11},\n priority = {2},\n title = {Scaling the walls of discovery: using semantic metadata for integrative problem solving},\n volume = {10}\n}\n\n@article{ citeulike:4200246,\n abstract = {The conversation about metadata quality has developed slowly in libraries, hindered by unexamined assumptions about metadata carrying over from experience in the MARC environment. In the wider world, discussions about functionality must drive discussions about how quality might be determined and ensured. Because the quality-enforcing structures present in the MARC worldmature standards, common documentation, and bibliographic utilitiesare lacking in the metadata world, metadata practitioners desiring to improve the quality of metadata used in their libraries must develop and proliferate their own processes of evaluation and transformation to support essential interoperability. In this article, the author endeavors to describe how those processes might be established and sustained to support metadata quality improvement.},\n author = {Diane I. Hillmann},\n citeulike-article-id = {4200246},\n doi = {10.1080/01639370802183008},\n journal = {Cataloging \\& Classification Quarterly},\n keyword = {metadata, quality},\n link = {http://dx.doi.org/10.1080/01639370802183008},\n number = {1},\n pages = {65--80},\n posted-at = {2009-06-05 14:34:42},\n priority = {0},\n publisher = {Routledge},\n title = {Metadata Quality: From Evaluation to Augmentation},\n volume = {46}\n}\n\n@article{ citeulike:4214520,\n abstract = {This paper assesses the range of equivalence or mapping types required to facilitate interoperability in the context of a distributed terminology server. A detailed set of mapping types were examined, with a view to determining their validity for characterizing relationships between mappings from selected terminologies (AAT, LCSH, MeSH, and UNESCO) to the Dewey Decimal Classification (DDC) scheme. It was hypothesized that the detailed set of 19 match types proposed by Chaplan in 1995 is unnecessary in this context and that they could be reduced to a less detailed conceptually-based set. Results from an extensive mapping exercise support the main hypothesis and a generic suite of match types are proposed, although doubt remains over the current adequacy of the developing Simple Knowledge Organization System (SKOS) Core Mapping Vocabulary Specification (MVS) for inter-terminology mapping. 10.1177/0165551507079130},\n author = {Emma Mcculloch and George Macgregor},\n citeulike-article-id = {4214520},\n doi = {10.1177/0165551507079130},\n journal = {Journal of Information Science},\n keyword = {mapping, terminology},\n link = {http://dx.doi.org/10.1177/0165551507079130},\n month = {February},\n number = {1},\n pages = {70--92},\n posted-at = {2009-06-30 16:39:43},\n priority = {2},\n title = {Analysis of equivalence mapping for terminology services},\n volume = {34},\n year = {2008}\n}\n\n@article{ citeulike:4217790,\n abstract = {Abstract Long-term digital preservation, the process of maintaining digital objects through time to ensure continued access, has become a crucial issue in recent years. Whilst the amount of digitised information is constantly increasing, so too is the pace of progress in information technology, resulting in obsolescence of the software and hardware required to access and view digital information. Despite many organisations recognising this threat and the resulting need for preservation action, more work is required to effectively address the issue. We present in this article a framework for the long-term digital preservation of 3-D data. This framework is based on two pertinent preservation practices, emulation and metadata which ensure that the authenticity and usability, respectively, of a preserved digital object remain intact through time. An evaluation of our framework is presented which illustrates the viability of our approach in retaining accessibility, authenticity and usability for future end users.},\n author = {Julie Doyle and Herna Viktor and Eric Paquet},\n citeulike-article-id = {4217790},\n citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00799-009-0051-7},\n citeulike-linkout-1 = {http://www.springerlink.com/content/r624114872486937},\n doi = {10.1007/s00799-009-0051-7},\n journal = {International Journal on Digital Libraries},\n keyword = {metadata, preservation},\n link = {http://dx.doi.org/10.1007/s00799-009-0051-7},\n pages = {33--47},\n posted-at = {2010-01-15 17:29:13},\n priority = {2},\n title = {Long-term digital preservation: preserving authenticity and usability of 3-D data}\n}\n\n@article{ citeulike:449907,\n abstract = {Metadata is designed to improve information organization and information retrieval effectiveness and efficiency on the Internet. The way web publishers respond to metadata and the way they use it when publishing their web pages, however, is still a mystery. The authors of this paper aim to solve this mystery by defining different professional publisher groups, examining the behaviors of these user groups, and identifying the characteristics of their metadata use. This study will enhance the current understanding of metadata application behavior and provide evidence useful to researchers, web publishers, and search engine designers.},\n author = {Jin Zhang and Iris Jastram},\n citeulike-article-id = {449907},\n citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.ipm.2005.05.002},\n citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6VC8-4GFCR46-1/2/5321b28f42e0511148600490ef64b23f},\n doi = {10.1016/j.ipm.2005.05.002},\n journal = {Information Processing \\& Management},\n keyword = {metadata, metadata\\_creation, metadata\\_quality},\n link = {http://dx.doi.org/10.1016/j.ipm.2005.05.002},\n month = {July},\n number = {4},\n pages = {1099--1122},\n posted-at = {2010-01-07 13:39:56},\n priority = {3},\n title = {A study of the metadata creation behavior of different user groups on the Internet},\n volume = {42},\n year = {2006}\n}\n\n@article{ citeulike:465841,\n abstract = {In image retrieval, most systems lack user-centred evaluation since they are assessed by some chosen ground truth dataset. The results reported through precision and recall assessed against the ground truth are thought of as being an acceptable surrogate for the judgment of real users. Much current research focuses on automatically assigning keywords to images for enhancing retrieval effectiveness. However, evaluation methods are usually based on system-level assessment, e.g. classification accuracy based on some chosen ground truth dataset. In this paper, we present a qualitative evaluation methodology for automatic image indexing systems. The automatic indexing task is formulated as one of image annotation, or automatic metadata generation for images. The evaluation is composed of two individual methods. First, the automatic indexing annotation results are assessed by human subjects. Second, the subjects are asked to annotate some chosen images as the test set whose annotations are used as ground truth. Then, the system is tested by the test set whose annotation results are judged against the ground truth. Only one of these methods is reported for most systems on which user-centred evaluation are conducted. We believe that both methods need to be considered for full evaluation. We also provide an example evaluation of our system based on this methodology. According to this study, our proposed evaluation methodology is able to provide deeper understanding of the system's performance.},\n author = {Chih-Fong Tsai and Ken Mcgarry and John Tait},\n citeulike-article-id = {465841},\n doi = {10.1016/j.ipm.2004.11.001},\n journal = {Information Processing \\& Management},\n keyword = {automatic\\_metadata\\_generation, evaluation},\n link = {http://dx.doi.org/10.1016/j.ipm.2004.11.001},\n month = {January},\n number = {1},\n pages = {136--154},\n posted-at = {2009-06-30 07:16:06},\n priority = {2},\n title = {Qualitative evaluation of automatic assignment of keywords to images},\n volume = {42},\n year = {2006}\n}\n\n@article{ citeulike:4746642,\n abstract = {With the advent and accessibility of the Internet, artistic and indigenous communities are beginning to realize how digital technologies can be used as a means for documenting and preserving their histories and cultures. However, it is not yet clear what knowledge architectures are most appropriate for creating a digital museum in order to facilitate an effective collection, organization, conservation, and experience of cultural and artistic heritage. In this paper, we discuss the concept of ” fluid ontologies,” a novel, dynamic structure for organizing and browsing knowledge in a digital museum. Fluid ontologies are flexible knowledge structures that evolve and adapt to communities' interest based on contextual information articulated by human contributors, curators, and viewers, as well as artificial bots that are able to track interaction histories and infer relationships among knowledge pieces and preferences of viewers. Fluid ontologies allow for a tighter coupling between communities' interests and the browsing structure of a digital museum. We present the key ideas behind the use of fluid ontologies within the context of digital museum design and seminal work in metadata/dynamic ontologies, particularly as it pertains to objects of cultural heritage, and discuss these characteristics in three concrete examples: (1) Village Voice, an online agora that ties together the narratives created by a group of Somali refugees using an iteration of community-designed ontologies, (2) Eventspace, a node-based collaborative archive for design activities, and (3) Tribal Peace, an online digital museum still under construction and evaluation that uses proactive agents to tie distributed Kumeyaay, Luiseno, and Cupeno reservations together in their quest to achieve greater political sovereignty .},\n author = {Ramesh Srinivasan and Jeffrey Huang},\n citeulike-article-id = {4746642},\n doi = {10.1007/s00799-004-0105-9},\n journal = {International Journal on Digital Libraries},\n keyword = {digital\\_museum, information\\_visualization, ontology},\n link = {http://dx.doi.org/10.1007/s00799-004-0105-9},\n month = {May},\n number = {3},\n pages = {193--204},\n posted-at = {2009-06-04 21:08:17},\n priority = {3},\n title = {Fluid ontologies for digital museums},\n volume = {5},\n year = {2005}\n}\n\n@incollection{ citeulike:4746665,\n abstract = {This study describes the building of ontologies to enhance current digital museum archives. Ontologies are employed to move the service level from information to knowledge retrieval. This study concentrates on a design procedure that exploits Formal Concept Analysis (FCA) to obtain conceptual structures, and Description Logic (DL) to denote concept relations in logic expressions. The empirical findings reveal that development procedures help guide ontology builders to build ontological knowledge bases step by step. Furthermore, the knowledge extraction is helpful and connectable for builders and other tools.},\n author = {Yu-Liang Chi},\n citeulike-article-id = {4746665},\n doi = {10.1007/11739685\\_31},\n journal = {Advances in Machine Learning and Cybernetics},\n keyword = {archive, ontology},\n link = {http://dx.doi.org/10.1007/11739685\\_31},\n pages = {295--304},\n posted-at = {2009-06-04 21:28:54},\n priority = {0},\n title = {Constructing Ontologies for Sharing Knowledge in Digital Archives},\n year = {2006}\n}\n\n@article{ citeulike:4746682,\n author = {Abdus S. Chaudhry and Tan P. Jiun},\n citeulike-article-id = {4746682},\n issn = {0022-0418},\n journal = {Journal of Documentation},\n keyword = {a, archive, digital\\_museum, taxonomy},\n number = {6},\n pages = {751--776},\n posted-at = {2009-06-04 21:47:07},\n priority = {3},\n publisher = {Emerald Group Publishing Limited},\n title = {Enhancing access to digital information resources on heritage: A case of development of a taxonomy at the Integrated Museum and Archives System in Singapore},\n volume = {61},\n year = {2005}\n}\n\n@article{ citeulike:4753116,\n author = {Xavier Ochoa and Erik Duval},\n citeulike-article-id = {4753116},\n keyword = {metadata, quality},\n link = {http://ariadne.cti.espol.edu.ec/M4M/files/TowardsAutomaticQuality.pdf},\n posted-at = {2009-06-05 15:51:21},\n priority = {0},\n title = {Towards Automatic Evaluation of Metadata Quality in Digital Repositories}\n}\n\n@article{ citeulike:4783697,\n abstract = {Contribution to a special issue on image access. Reports on a quantitative categorical analysis of metadata elements in the Dublin Core, VRA Core, REACH and EAD metadata schemas, all of which can be used for organizing and describing images. Found that each of the examined metadata schemas contains elements that support the discovery, use, authentication and administration of images, and that the number and proportion of elements supporting functions in these classes varies per schema. Introduces a new schema comparison methodology and explores the development of a class oriented functional metadata schema for controlling images across multiple domains. (Original abstract - amended)},\n author = {Jane Greenberg},\n citeulike-article-id = {4783697},\n citeulike-linkout-0 = {http://dx.doi.org/10.1002/asi.1170.abs},\n doi = {10.1002/asi.1170.abs},\n journal = {Journal of the American Society for Information Science and Technology},\n keyword = {image, metadata, metadata\\_standards},\n link = {http://dx.doi.org/10.1002/asi.1170.abs},\n number = {11},\n pages = {917--924},\n posted-at = {2009-09-25 21:25:13},\n priority = {0},\n title = {A quantitative categorical analysis of metadata elements in image-applicable metadata schemas},\n volume = {52},\n year = {2001}\n}\n\n@article{ citeulike:4783742,\n abstract = {This paper reports on the automatic metadata generation applications (AMeGA) project's metadata expert survey. Automatic metadata generation research is reviewed and the study's methods, key findings and conclusions are presented. Participants anticipate greater accuracy with automatic techniques for technical metadata (e.g., ID, language, and format metadata) compared to metadata requiring intellectual discretion (e.g., subject and description metadata). Support for implementing automatic techniques paralleled anticipated accuracy results. Metadata experts are in favour of using automatic techniques, although they are generally not in favour of eliminating human evaluation or production for the more intellectually demanding metadata. Results are incorporated into Version 1.0 of the Recommended Functionalities for automatic metadata generation applications (Appendix A).},\n author = {Jane Greenberg and Kristina Spurgin and Abe Crystal},\n citeulike-article-id = {4783742},\n journal = {International Journal of Metadata, Semantics and Ontologies},\n number = {1},\n pages = {3--20},\n posted-at = {2009-06-30 06:28:48},\n priority = {2},\n title = {Functionalities for automatic metadata generation applications: a survey of metadata experts' opinions},\n volume = {1},\n year = {2006}\n}\n\n@article{ citeulike:4867464,\n author = {Lois M. Chan and Marcia L. Zeng},\n citeulike-article-id = {4867464},\n doi = {10.1045/june2006-chan},\n journal = {D-Lib Magazine},\n keyword = {interoperability, metadata},\n link = {http://dx.doi.org/10.1045/june2006-chan},\n month = {June},\n number = {6},\n posted-at = {2009-06-30 17:08:16},\n priority = {2},\n title = {Metadata Interoperability and Standardization -- A Study of Methodology Part I Achieving Interoperability at the Schema Level},\n volume = {12},\n year = {2006}\n}\n\n@article{ citeulike:4867619,\n author = {Marcia L. Zeng and Lois M. Chan},\n citeulike-article-id = {4867619},\n doi = {10.1045/june2006-zeng},\n journal = {D-Lib Magazine},\n keyword = {interoperability, metadata},\n link = {http://dx.doi.org/10.1045/june2006-zeng},\n month = {June},\n number = {6},\n posted-at = {2009-06-30 17:07:04},\n priority = {2},\n title = {Metadata Interoperability and Standardization -- A Study of Methodology Part II Achieving Interoperability at the Record and Repository Levels},\n volume = {12},\n year = {2006}\n}\n\n@phdthesis{ citeulike:4889962,\n author = {Michel Klein},\n citeulike-article-id = {4889962},\n citeulike-linkout-0 = {http://www.cs.vu.nl/~mcaklein/thesis/},\n link = {http://www.cs.vu.nl/~mcaklein/thesis/},\n month = {August},\n posted-at = {2009-11-25 14:37:08},\n priority = {2},\n school = {Vrije Universiteit Amsterdam},\n title = {Change Management for Distributed Ontologies}\n}\n\n@article{ citeulike:4926312,\n address = {Los Alamitos, CA, USA},\n author = {Yorick Wilks},\n citeulike-article-id = {4926312},\n doi = {http://doi.ieeecomputersociety.org/10.1109/MIS.2008.53},\n journal = {IEEE Intelligent Systems},\n keyword = {semantic\\_web, semantics},\n link = {http://dx.doi.org/http://doi.ieeecomputersociety.org/10.1109/MIS.2008.53},\n number = {3},\n pages = {41--49},\n posted-at = {2009-06-30 05:55:48},\n priority = {3},\n publisher = {IEEE Computer Society},\n title = {The Semantic Web: Apotheosis of Annotation, but What Are Its Semantics?},\n volume = {23}\n}\n\n@article{ citeulike:4981688,\n abstract = {Reports results of a study to examine interindexer consistency (the degree to which indexers, when assigning terms to a chosen record, will choose the same terms to reflect that record) in the PsycINFO database using 60 records that were inadvertently processed twice between 1996 and 1998. Five aspects of interindexer consistency were analysed. Two methods were used to calculate interindexer consistency: one posited by Hooper (1965) and the other by Rollin (1981). Aspects analysed were: checktag consistency (66.24\\% using Hooper's calculation and 77.17\\% using Rollin's); major-to-all term consistency (49.31\\% and 62.59\\% respectively); overall indexing consistency (49.02\\% and 63.32\\%); classification code consistency (44.17\\% and 45.00\\%); and major-to-major term consistency (43.24\\% and 56.09\\%). The average consistency across all categories was 50.4\\% using Hooper's method and 60.83\\% using Rollin's. Although comparison with previous studies is difficult due to methodological variations in the overall study of indexing consistency and the specific characteristics of the database, results generally support previous findings when trends and similar studies are analysed. 10.1177/096100060003200102},\n author = {Kurt Leininger},\n citeulike-article-id = {4981688},\n citeulike-linkout-0 = {http://dx.doi.org/10.1177/096100060003200102},\n citeulike-linkout-1 = {http://lis.sagepub.com/cgi/content/abstract/32/1/4},\n day = {1},\n doi = {10.1177/096100060003200102},\n journal = {Journal of Librarianship and Information Science},\n keyword = {interindexer\\_consistency},\n link = {http://dx.doi.org/10.1177/096100060003200102},\n month = {March},\n number = {1},\n pages = {4--8},\n posted-at = {2010-03-14 00:15:27},\n priority = {2},\n title = {Interindexer consistency in PsycINFO},\n volume = {32}\n}\n\n@article{ citeulike:4981874,\n abstract = {Describes a study that was conducted to determine how well subject authority lists, or thesauri, control indexing vocabulary. Indexer consistency using the Commonwealth Agricultural Bureaux (CAB) thesaurus was tested by comparing indexing done by CAB and by National Agricultural Library (NAL) indexers. (six references) (LRW)},\n author = {Phyllis Reich and Erik J. Biever},\n citeulike-article-id = {4981874},\n citeulike-linkout-0 = {http://www.eric.ed.gov/ERICWebPortal/detail?accno=EJ430272},\n day = {0},\n journal = {College and Research Libraries},\n keyword = {indexerconsistency, indexing, paper1, thesaurus, thesis},\n link = {http://www.eric.ed.gov/ERICWebPortal/detail?accno=EJ430272},\n month = {},\n number = {4},\n pages = {336--42},\n posted-at = {2009-06-26 20:57:47},\n priority = {0},\n title = {Indexing Consistency: The Input/Output Function of Thesauri.},\n volume = {52}\n}\n\n@article{ citeulike:5024113,\n abstract = {The quality of the metadata records in a digital library has a critical effect on its information access and retrieval. The open source Metadata Repository at the National Science Digital Library {(NSDL)} comprises of collections of metadata submitted from various data providers and is open for harvesting by the public. Since metadata in the repository came from many different data providers, there is a lack of consistency. This lack of consistent hampers the information services provided by the {NSDL} to its own web users as well as to aggregators who harvest the {NSDL} data. The goal of this study is to assess the quality of the current metadata records in the {NSDL} Repository. We harvested over one million Dublin Core metadata records submitted through November 2005 to the repository using the Open Archives Initiative Protocol {(OAIP).} The data harvested was loaded into an Excel database and exhaustive tabulations of all the Dublin Core metadata fields were performed. The criteria of quality assessment are based on the following areas: consistency, completeness, accuracy and local additions of data providers. This study reports on the results of the tabulations and assessment of metadata quality. Information organizations and institutions will benefit from the results of this study in determining which parts of the repository they aim to harvest. The data collected for this study will be made available to the public to contribute to promoting studies on metadata quality improvement by enabling other researchers to have access to the data for further analysis.},\n author = {Yen Bui and Jung-Ran Park},\n citeulike-article-id = {5024113},\n keyword = {metadata, metadata\\_quality},\n link = {http://idea.library.drexel.edu/handle/1860/1600},\n pages = {1--13},\n posted-at = {2009-06-30 17:41:23},\n priority = {2},\n title = {An assessment of metadata quality: A case study of the National Science Digital Library Metadata Repository},\n year = {2006}\n}\n\n@book{ citeulike:5025939,\n abstract = {In this new, authoritative textbook, internationally recognized metadata experts Zeng and Qin have created a comprehensive primer for advanced undergraduate, graduate, or continuing education courses in information organization, information technology, cataloging, digital libraries, electronic archives, and, of course, metadata. Instructors seeking a text that covers the theory as well as the how-to's of application design, implementation, and evaluation will find it here. An outcome-based approach lets learners with different orientations adapt their new knowledge and skills to any domain. Examples and practice problems focus on tasks typical to all metadata application projects. Other useful features include sample problems with solutions, quizzes, hands-on tutorials, and a recommended reading list at the end of each chapter.},\n address = {New York},\n author = {Macial L. Zeng and Jian Qin},\n citeulike-article-id = {5025939},\n edition = {First},\n isbn = {1555706355},\n keyword = {metadata},\n pages = {1--365},\n posted-at = {2009-06-30 19:59:51},\n priority = {0},\n publisher = {Neal-Schuman Publishers},\n title = {Metadata}\n}\n\n@article{ citeulike:5153351,\n abstract = {Purpose: To explain the background, functionality, and content of the CARL metadata harvester and search service, http: //carl-abrc-oai.lib.sfu.ca/, and to outline plans for improving the service. Design/methodology/approach: This case study employs simple statistical analyses to a set of harvested metadata. Findings: This paper documents the use of unqualified Dublin Core (uDC) elements in the metadata harvested from the repositories participating in the CARL harvester, and identifies patterns in the use of that metadata. It also compares these findings with a similar study, and identifies areas for further research. Research limitations/implications: This paper is limited to discussion of the characteristics of a relatively small set of metadata collected using the Open Archives Initiative Protocol for Metadata Harvesting. However, analyses reveal some patterns in the use of this metadata that are valuable in the development of best practices for repository implementers. Practical implications: This paper documents the use of uDC elements by a specific community. Its findings will form a basis for developing mechanisms for improving the effectiveness of the metadata generated by that community and therefore the services built around that metadata. Originality/value: While there are several other studies that take an approach similar to that taken in this paper, no one has yet studied this specific data set. More generally, this paper contributes a valuable case study to research on the implementation of the Open Archives Initiative Protocol for Metadata Harvesting. (Author abstract)},\n author = {Mark Jordan},\n citeulike-article-id = {5153351},\n citeulike-linkout-0 = {http://dx.doi.org/doi:10.1108/07378830610669574},\n doi = {doi:10.1108/07378830610669574},\n journal = {Library Hi Tech,},\n link = {http://dx.doi.org/doi:10.1108/07378830610669574},\n number = {2},\n pages = {197--210},\n posted-at = {2010-01-15 15:03:45},\n priority = {2},\n title = {The CARL metadata harvester and search service},\n volume = {24}\n}\n\n@book{ citeulike:524985,\n author = {G. G. Chowdhury and Sudatta Chowdhury},\n citeulike-article-id = {524985},\n howpublished = {Paperback},\n isbn = {1856044653},\n keyword = {digital\\_library},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/1856044653},\n month = {November},\n posted-at = {2009-06-30 19:30:45},\n priority = {2},\n publisher = {Facet Publishing},\n title = {Introduction to Digital Libraries}\n}\n\n@article{ citeulike:5497773,\n abstract = {Abstract Owing to the recent developments in automatic metadata generation and interoperability between digital repositories, the production of metadata is now vastly surpassing manual quality control capabilities. Abandoning quality control altogether is problematic, because low-quality metadata compromise the effectiveness of services that repositories provide to their users. To address this problem, we present a set of scalable quality metrics for metadata based on the Bruce \\& Hillman framework for metadata quality control. We perform three experiments to evaluate our metrics: (1) the degree of correlation between the metrics and manual quality reviews, (2) the discriminatory power between metadata sets and (3) the usefulness of the metrics as low-quality filters. Through statistical analysis, we found that several metrics, especially Text Information Content, correlate well with human evaluation and that the average of all the metrics are roughly as effective as people to flag low-quality instances. The implications of this finding are discussed. Finally, we propose possible applications of the metrics to improve tools for the administration of digital repositories.},\n author = {Xavier Ochoa and Erik Duval},\n citeulike-article-id = {5497773},\n citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00799-009-0054-4},\n citeulike-linkout-1 = {http://www.springerlink.com/content/0830860110v30832},\n doi = {10.1007/s00799-009-0054-4},\n journal = {International Journal on Digital Libraries},\n keyword = {metadata\\_quality, metrics},\n link = {http://dx.doi.org/10.1007/s00799-009-0054-4},\n month = {August},\n number = {2-3},\n pages = {67--91},\n posted-at = {2010-01-07 05:27:19},\n priority = {0},\n title = {Automatic evaluation of metadata quality in digital repositories},\n volume = {10},\n year = {2009}\n}\n\n@article{ citeulike:559522,\n abstract = {The semantic Web vision of a \"unifying logical language that enables concepts to be progressively linked into a universal Web\" is part of along lineage of dreams of a universal repository of ideas: from Diderot's universal encyclopedia in the 18th century to Vannevar Bush's Memex at the beginning of the computer age to Ted Nelson's Xanadu in the 1970s. However, the semantic Web's development so far has focused primarily on metadata and carefully designed data structures. To realize Berners-Lee's vision, the semantic Web must capture and represent content created every day by people without special training - such content includes blogs, emails, and discussion groups. Rhizome is an experimental, open source content management framework the author have created that can capture and represent informal, human-authored content in a semantically rich manner. Rhizome aims to help bring about a new kind of commons - one of ideas. This commons wouldn't comprise just a web of interlinked pages of content, as is the current World Wide Web, but a web of relationships between the underlying ideas and distinctions that the content implies: a permanent, universally accessible interlinking of content based on imputed semantics such as concepts, definitions, or structured argumentation.},\n author = {A. Souzis},\n citeulike-article-id = {559522},\n journal = {Intelligent Systems, IEEE [see also IEEE Intelligent Systems and Their Applications]},\n keyword = {semantic\\_web, semantic\\_wiki},\n link = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1512004},\n number = {5},\n pages = {87--91},\n posted-at = {2009-06-30 16:02:56},\n priority = {2},\n title = {Building a semantic wiki},\n volume = {20},\n year = {2005}\n}\n\n@article{ citeulike:5721593,\n abstract = {This article describes a model for online consumer health information consisting of five quality criteria constructs. These constructs are grounded in empirical data from the perspectives of the three main sources in the communication process: health information providers, consumers, and intermediaries, such as Web directory creators and librarians, who assist consumers in finding healthcare information. The article also defines five constructs of Web page structural markers that could be used in information quality evaluation and maps these markers to the quality criteria. Findings from correlation analysis and multinomial logistic tests indicate that use of the structural markers depended significantly on the type of Web page and type of information provider. The findings suggest the need to define genre-specific templates for quality evaluation and the need to develop models for an automatic genre-based classification of health information Web pages. In addition, the study showed that consumers may lack the motivation or literacy skills to evaluate the information quality of health Web pages, which suggests the need to develop accessible automatic information quality evaluation tools and ontologies.},\n author = {Besiki Stvilia and Lorri Mon and Yong J. Yi},\n citeulike-article-id = {5721593},\n citeulike-linkout-0 = {http://dx.doi.org/10.1002/asi.21115},\n doi = {10.1002/asi.21115},\n issn = {15322882},\n journal = {Journal of the American Society for Information Science and Technology},\n link = {http://dx.doi.org/10.1002/asi.21115},\n month = {September},\n number = {9},\n pages = {1781--1791},\n posted-at = {2010-01-15 14:32:58},\n priority = {2},\n title = {A model for online consumer health information quality},\n volume = {60}\n}\n\n@article{ citeulike:5730605,\n author = {Alistair Black},\n citeulike-article-id = {5730605},\n citeulike-linkout-0 = {http://dx.doi.org/DOI:10.1002/aris.1440400118},\n doi = {DOI:10.1002/aris.1440400118},\n journal = {Annual Review of Information Science \\& Technology (ARIST)},\n keyword = {information\\_history},\n link = {http://dx.doi.org/DOI:10.1002/aris.1440400118},\n pages = {441--473},\n posted-at = {2009-09-07 02:47:02},\n priority = {0},\n title = {Information history},\n volume = {40},\n year = {2006}\n}\n\n@article{ citeulike:5730696,\n author = {Rayward W. Boyd},\n citeulike-article-id = {5730696},\n citeulike-linkout-0 = {http://dx.doi.org/doi:10.1016/0306-4573(95)00046-J},\n doi = {doi:10.1016/0306-4573(95)00046-J},\n issn = {0306-4573},\n journal = {Information Processing and Management},\n keyword = {information\\_history},\n link = {http://dx.doi.org/doi:10.1016/0306-4573(95)00046-J},\n number = {1},\n pages = {3--17},\n posted-at = {2009-09-07 03:22:17},\n priority = {0},\n title = {The history and historiography of information science: Some reflections},\n volume = {32},\n year = {1996}\n}\n\n@book{ citeulike:5781773,\n author = {Sebastian R. Kruk and W. D. McDaniel},\n citeulike-article-id = {5781773},\n citeulike-linkout-0 = {http://www.worldcat.org/isbn/9783540854333},\n citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9783540854333},\n citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9783540854333\\&index=books\\&linkCode=qs},\n citeulike-linkout-3 = {http://www.librarything.com/isbn/9783540854333},\n citeulike-linkout-4 = {http://www.worldcat.org/oclc/243822188},\n isbn = {9783540854333},\n keyword = {digital, library, semantic},\n link = {http://www.worldcat.org/isbn/9783540854333},\n posted-at = {2009-09-14 20:08:58},\n priority = {2},\n publisher = {Springer},\n title = {Semantic digital libraries},\n year = {2009}\n}\n\n@article{ citeulike:5784891,\n author = {Jung-ran Park and Susan Msazaros},\n citeulike-article-id = {5784891},\n journal = {Knowledge Organization},\n keyword = {metadata, metadata\\_quality},\n number = {1},\n pages = {46--59},\n posted-at = {2009-09-15 01:53:34},\n priority = {0},\n title = {Metadata Object Description Schema (MODS) in Digital Repositories: An Exploratory Study of Metadata Use and Quality},\n volume = {36}\n}\n\n@article{ citeulike:5792203,\n author = {Jung-ran Park},\n citeulike-article-id = {5792203},\n journal = {Knowledge Organization},\n keyword = {digital\\_image\\_collections, metadata\\_quality, semantic\\_interoperability},\n number = {1},\n pages = {20--34},\n posted-at = {2009-09-16 17:03:03},\n priority = {3},\n title = {Semantic Interoperability and Metadata Quality: An Analysis of Metadata Item Records of Digital Image Collections},\n volume = {33}\n}\n\n@article{ citeulike:5800826,\n author = {Eun G. Park},\n citeulike-article-id = {5800826},\n citeulike-linkout-0 = {http://dx.doi.org/10.1108/02640470710741331},\n doi = {10.1108/02640470710741331},\n issn = {0264-0473},\n journal = {The Electronic Library},\n keyword = {metadata, metadata\\_assessment},\n link = {http://dx.doi.org/10.1108/02640470710741331},\n number = {2},\n pages = {207--218},\n posted-at = {2009-09-18 00:56:42},\n priority = {0},\n publisher = {Emerald Group Publishing Limited},\n title = {Building interoperable Canadian architecture collections: initial metadata assessment},\n volume = {25},\n year = {2007}\n}\n\n@incollection{ citeulike:5800838,\n author = {S. A. Knight and A. Spink},\n booktitle = {Web Search},\n citeulike-article-id = {5800838},\n citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-75829-7\\\\_12},\n doi = {10.1007/978-3-540-75829-7\\_12},\n editor = {A. Spink and M. Zimmer},\n issn = {1568-1300},\n keyword = {information\\_behaviour, model},\n link = {http://dx.doi.org/10.1007/978-3-540-75829-7_12},\n pages = {209--234},\n posted-at = {2009-09-18 01:08:52},\n priority = {3},\n publisher = {Springer Berlin Heidelberg},\n title = {Toward a Web Search Information Behavior Model},\n year = {2008}\n}\n\n@book{ citeulike:587164,\n abstract = {Ontologies provide a common vocabulary of an area and define, with different levels of formality, the meaning of the terms and the relationships between them. Ontological engineering refers to the set of activities concerning the ontology development process, the ontology life cycle, the methods and methodologies for building ontologies, and the tool suites and languages that support them. During the last decade, increasing attention has been focused on ontologies. Ontologies are now widely used in knowledge engineering, artificial intelligence and computer science; in applications related to areas such as knowledge management, natural language processing, e-commerce, intelligent information integration, bio-informatics, education; and in new emerging fields like the semantic web. The book presents the major issues of ontological engineering and describes the most outstanding ontologies currently available. It covers the practical aspects of selecting and applying methodologies, languages, and tools for building ontologies. Ontological Engineering will be of great value to students and researchers, and to developers who want to integrate ontologies in their information systems. },\n author = {Asuncion Gomez-Perez and Oscar Corcho and Mariano Fernandez-Lopez},\n citeulike-article-id = {587164},\n howpublished = {Hardcover},\n isbn = {1852335513},\n keyword = {ontology, semantic\\_web},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/1852335513},\n month = {July},\n posted-at = {2009-06-30 19:52:40},\n priority = {0},\n publisher = {Springer},\n title = {Ontological Engineering : with examples from the areas of Knowledge Management, e-Commerce and the Semantic Web. First Edition (Advanced Information and Knowledge Processing)}\n}\n\n@article{ citeulike:5894543,\n author = {Charlotte Jenkins and Mike Jackson and Peter Burden and Jon Wallis},\n citeulike-article-id = {5894543},\n citeulike-linkout-0 = {http://74.125.155.132/scholar?q=cache:6NBDemQboWwJ:scholar.google.com/+dewey+decimal+system\\&\\\\#38;hl=en},\n day = {8},\n journal = {Computer Networks},\n keyword = {metadata, metadata\\_generation, rdf},\n link = {http://74.125.155.132/scholar?q=cache:6NBDemQboWwJ:scholar.google.com/+dewey+decimal+system&#38;hl=en},\n month = {May},\n pages = {1305--1320},\n posted-at = {2010-01-15 02:58:35},\n priority = {3},\n title = {Automatic RDF Metadata Generation for Resource Discovery},\n volume = {31},\n year = {2003}\n}\n\n@article{ citeulike:5944328,\n abstract = {Digital libraries (DLs) are complex information systems which can present changes in their structure, content, and services. These complexities and dynamics make system maintenance a non-trivial task, since it requires periodical evaluation of the different DL components. Generally, these evaluations are customized per system and are performed only when problems occur and administrator intervention is required. This work aims to change the situation. We present 5SQual, a tool which provides ways to perform automatic and configurable evaluations of some of the most important DL components, among them, digital objects, metadata, and services. The tool implements diverse numeric indicators that are associated with eight quality dimensions described in the 5S quality model. Its generic architecture was developed to be applicable to various DLs and scenarios. In sum, the main contributions of this work include: (i) the design and implementation of 5SQual, a tool that validates a theoretical DL quality model; (ii) the demonstration of the applicability of the tool in several usage scenarios; and (iii) the evaluation (with usability specialists) of its graphical interface specially designed to guide the configuration of 5SQual evaluations. We also present the results of interviews conducted with administrators of real DLs regarding their expectations and opinions about 5SQual.},\n author = {B{\\'a}rbara L. Moreira and Marcos A. Gon\\c{c}alves and Alberto H. F. Laender and Edward A. Fox},\n citeulike-article-id = {5944328},\n citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.joi.2008.12.003},\n citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1751157708000734},\n doi = {10.1016/j.joi.2008.12.003},\n issn = {17511577},\n journal = {Journal of Informetrics},\n keyword = {digital\\_library, evaluation},\n link = {http://dx.doi.org/10.1016/j.joi.2008.12.003},\n month = {April},\n number = {2},\n pages = {102--123},\n posted-at = {2010-01-15 14:03:03},\n priority = {2},\n title = {Automatic evaluation of digital libraries with 5SQual},\n volume = {3}\n}\n\n@incollection{ citeulike:6071587,\n abstract = {The mathematical concept of document resemblance captures well the informal notion of syntactic similarity. The resemblance can be estimated using a fixed size ” sketch” for each document. For a large collection of documents (say hundreds of millions) the size of this sketch is of the order of a few hundred bytes per document. However, for efficient large scale web indexing it is not necessary to determine the actual resemblance value: it suffices to determine whether newly encountered documents are duplicates or near-duplicates of documents already indexed. In other words, it suffices to determine whether the resemblance is above a certain threshold. In this talk we show how this determination can be made using a ” sample” of less than 50 bytes per document. The basic approach for computing resemblance has two aspects: first, resemblance is expressed as a set (of strings) intersection problem, and second, the relative size of intersections is evaluated by a process of random sampling that can be done independently for each document. The process of estimating the relative size of intersection of sets and the threshold test discussed above can be applied to arbitrary sets, and thus might be of independent interest. The algorithm for filtering near-duplicate documents discussed here has been successfully implemented and has been used for the last three years in the context of the AltaVista search engine.},\n author = {Andrei Broder},\n citeulike-article-id = {6071587},\n citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-45123-4\\\\_1},\n citeulike-linkout-1 = {http://www.springerlink.com/content/ktn21yjul3r379xy},\n doi = {10.1007/3-540-45123-4\\_1},\n journal = {Combinatorial Pattern Matching},\n link = {http://dx.doi.org/10.1007/3-540-45123-4_1},\n pages = {1--10},\n posted-at = {2010-01-15 14:18:25},\n priority = {2},\n title = {Identifying and Filtering Near-Duplicate Documents}\n}\n\n@article{ citeulike:6081565,\n abstract = {The Web is ephemeral. Many resources have representations that change overtime, and many of those representations are lost forever. A lucky few manage toreappear as archived resources that carry their own URIs. For example, somecontent management systems maintain version pages that reflect a frozen priorstate of their changing resources. Archives recurrently crawl the web to obtainthe actual representation of resources, and subsequently make those availablevia special-purpose archived resources. In both cases, the archival copies haveURIs that are protocol-wise disconnected from the URI of the resource of whichthey represent a prior state. Indeed, the lack of temporal capabilities in themost common Web protocol, HTTP, prevents getting to an archived resource on thebasis of the URI of its original. This turns accessing archived resources intoa significant discovery challenge for both human and software agents, whichtypically involves following a multitude of links from the original to thearchival resource, or of searching archives for the original URI. This paperproposes the protocol-based Memento solution to address this problem, anddescribes a proof-of-concept experiment that includes major servers of archivalcontent, including Wikipedia and the Internet Archive. The Memento solution isbased on existing HTTP capabilities applied in a novel way to add the temporaldimension. The result is a framework in which archived resources can seamlesslybe reached via the URI of their original: protocol-based time travel for theWeb.},\n archiveprefix = {arXiv},\n author = {Herbert {Van de Sompel} and Michael L. Nelson and Robert Sanderson and Lyudmila L. Balakireva and Scott Ainsworth and Harihar Shankar},\n citeulike-article-id = {6081565},\n citeulike-linkout-0 = {http://arxiv.org/abs/0911.1112},\n citeulike-linkout-1 = {http://arxiv.org/pdf/0911.1112},\n day = {6},\n eprint = {0911.1112},\n link = {http://arxiv.org/abs/0911.1112},\n month = {Nov},\n posted-at = {2010-01-15 16:54:27},\n priority = {0},\n title = {Memento: Time Travel for the Web}\n}\n\n@phdthesis{ citeulike:6086656,\n author = {Besiki Stvilia},\n citeulike-article-id = {6086656},\n citeulike-linkout-0 = {http://proquest.umi.com/pqdweb?did=1192183091\\&\\\\#38;sid=3\\&\\\\#38;Fmt=2\\&\\\\#38;clientId=10843\\&\\\\#38;RQT=309\\&\\\\#38;VName=PQD},\n institution = {UIUC},\n keyword = {information\\_quality, measurment, metadata\\_quality},\n link = {http://proquest.umi.com/pqdweb?did=1192183091&#38;sid=3&#38;Fmt=2&#38;clientId=10843&#38;RQT=309&#38;VName=PQD},\n posted-at = {2009-11-08 21:28:06},\n priority = {0},\n publisher = {UIUC},\n title = {Measuring Information Quality},\n year = {2007}\n}\n\n@inproceedings{ citeulike:621108,\n author = {Mikael Nilsson and Matthias Parlmer and Ambjorn Naeve},\n booktitle = {Proceedings of the 11th World Wide Web Conference (WWW2002)},\n citeulike-article-id = {621108},\n citeulike-linkout-0 = {http://wwwconf.ecs.soton.ac.uk/archive/00000221/01/},\n citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.12.7652\\&\\\\#38;rep=rep1\\&\\\\#38;type=url\\&\\\\#38;i=0},\n link = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.12.7652&rep=rep1&type=url&i=0},\n location = {Hawaii, USA},\n month = {March},\n pages = {1--22},\n posted-at = {2010-01-15 20:23:24},\n priority = {2},\n title = {Semantic Web Metadata for e-Learning - Some Architectural Guidelines}\n}\n\n@book{ citeulike:622433,\n abstract = {As the World Wide Web continues to expand, it becomes increasingly difficult for users to obtain information efficiently. Because most search engines read format languages such as HTML or SGML, search results reflect formatting tags more than actual page content, which is expressed in natural language. <i>Spinning the Semantic Web</i> describes an exciting new type of hierarchy and standardization that will replace the current \"web of links\" with a \"web of meaning.\" Using a flexible set of languages and tools, the Semantic Web will make all available information -- display elements, metadata, services, images, and especially content -- accessible. The result will be an immense repository of information accessible for a wide range of new applications.<br /> <br /> This first handbook for the Semantic Web covers, among other topics, software agents that can negotiate and collect information, markup languages that can tag many more types of information in a document, and knowledge systems that enable machines to read Web pages and determine their reliability. The truly interdisciplinary Semantic Web combines aspects of artificial intelligence, markup languages, natural language processing, information retrieval, knowledge representation, intelligent agents, and databases.},\n author = {Dieter Fensel and James A. Hendler and Henry Lieberman and Wolfgang Wahlster},\n citeulike-article-id = {622433},\n howpublished = {Paperback},\n isbn = {026256212X},\n keyword = {semantic\\_web},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/026256212X},\n month = {March},\n posted-at = {2009-06-30 20:24:32},\n priority = {2},\n publisher = {The MIT Press},\n title = {Spinning the Semantic Web : Bringing the World Wide Web to Its Full Potential}\n}\n\n@incollection{ citeulike:6235902,\n abstract = {Ontologies on the Semantic Web form a basis for representing human-conceivable knowledge in a machine-understandable manner. Ontology development for a specific knowledge domain is however a difficult task, because the produced representation has to be adequately detailed and broad enough at the same time. The CIDOC-CRM is such an ontology, pertaining to cultural heritage, which we align to the Semantic Web environment: first transforming it to OWL and then profiling it not in the usual flat metadata sense, but by refining and extending its conceptual structures, taking advantage of OWL semantics. This kind of profiling maintains applicability of the model, while enabling more expressive reasoning tasks. To this end, we construct a mechanism for acquiring implied and web-distributed information that is used to conduct and present a series of experimental inferences on the CRM profiled form.},\n author = {Dimitrios A. Koutsomitropoulos and George E. Paloukis and Theodore S. Papatheodorou},\n citeulike-article-id = {6235902},\n citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-0-387-77745-0\\\\_3},\n citeulike-linkout-1 = {http://www.springerlink.com/content/m68460003gu7772p},\n doi = {10.1007/978-0-387-77745-0\\_3},\n journal = {Metadata and Semantics},\n link = {http://dx.doi.org/10.1007/978-0-387-77745-0_3},\n pages = {23--33},\n posted-at = {2010-01-16 02:27:49},\n priority = {2},\n title = {Semantic Application Profiles: A Means to Enhance Knowledge Discovery in Domain Metadata Models},\n year = {2009}\n}\n\n@incollection{ citeulike:6255343,\n abstract = {Even though the Dublin Core Metadata Element Set is well accepted as a general solution, it fails to describe more complex information assets and their cross-correlation. These include data from political history, history of arts and sciences, archaeology or observational data from natural history or geosciences. Therefore IFLA and ICOM are merging their core ontologies, an important step towards semantic interoperability of metadata schemata across all archives, libraries and museums. It opens new prospects for advanced global information integration services. The first draft of the combined model was published in June 2006.},\n author = {Martin Doerr and Patrick LeBoeuf},\n citeulike-article-id = {6255343},\n citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-77088-6\\\\_11},\n doi = {10.1007/978-3-540-77088-6\\_11},\n journal = {Digital Libraries: Research and Development},\n keyword = {cidoc, frbr},\n link = {http://dx.doi.org/10.1007/978-3-540-77088-6_11},\n pages = {114--123},\n posted-at = {2010-01-16 02:09:02},\n priority = {2},\n title = {Modelling Intellectual Processes: The FRBR - CRM Harmonization}\n}\n\n@incollection{ citeulike:6443492,\n abstract = {Large amounts of data in modern information systems, such as the World Wide Web, require innovative information retrieval techniques to effectively satisfy users' information need. A promising approach is to exploit document semantics in the IR process. For this purpose, high-quality semantic metadata is needed. This paper introduces a method to automatically create semantic metadata by using ontologically enhanced versions of common information extraction methods, such as named entity recognition and coreference resolution. Furthermore, this work also proposes the application of ontology-specific heuristic rules to further improve the quality of generated metadata. The results of our method was evaluated using a small test collection.},\n author = {{\\\"U}mit Yoldas and G{\\'a}bor Nagyp{\\'a}l},\n booktitle = {On the Move to Meaningful Internet Systems 2006: CoopIS, DOA, GADA, and ODBASE},\n chapter = {48},\n citeulike-article-id = {6443492},\n citeulike-linkout-0 = {http://dx.doi.org/10.1007/11914853\\\\_48},\n citeulike-linkout-1 = {http://www.springerlink.com/content/hvq2024wwh826425},\n doi = {10.1007/11914853\\_48},\n link = {http://dx.doi.org/10.1007/11914853_48},\n pages = {791--806},\n posted-at = {2010-01-15 17:44:52},\n priority = {2},\n series = {Lecture Notes in Computer Science},\n title = {Ontology Supported Automatic Generation of High-Quality Semantic Metadata}\n}\n\n@article{ citeulike:6497016,\n author = {Stuart A. Sutton},\n citeulike-article-id = {6497016},\n citeulike-linkout-0 = {http://dx.doi.org/doi:10.1080/01639370802183065},\n doi = {doi:10.1080/01639370802183065},\n journal = {Cataloging \\& Classification Quarterly},\n keyword = {metadata\\_quality, semantic\\_web},\n link = {http://dx.doi.org/doi:10.1080/01639370802183065},\n month = {September},\n number = {1},\n pages = {81--107},\n posted-at = {2010-01-07 05:04:27},\n priority = {0},\n title = {Metedata Quality, Utility and the Semantic Web: The Case of Learning Resources and Archievement Standards},\n volume = {46},\n year = {2008}\n}\n\n@article{ citeulike:6544271,\n abstract = {This paper describes a conceptual framework and methodology for managing scheme versioning for the Semantic Web. The first part of the paper introduces the concept of vocabulary encoding schemes, distinguished from metadata schemas, and discusses the characteristics of changes in schemes. The paper then presents a proposal to use a value record-similar to a term record in thesaurus management techniques-to manage scheme versioning challenges for the Semantic Web. The conclusion identifies future research directions.},\n author = {Joseph T. Tennis},\n citeulike-article-id = {6544271},\n citeulike-linkout-0 = {http://dx.doi.org/10.1300/J104v43n03\\\\_05},\n doi = {10.1300/J104v43n03\\_05},\n journal = {Cataloging \\& Classification Quarterly},\n link = {http://dx.doi.org/10.1300/J104v43n03_05},\n number = {3},\n pages = {85--104},\n posted-at = {2010-01-15 14:31:16},\n priority = {2},\n publisher = {Routledge},\n title = {Scheme Versioning in the Semantic Web},\n volume = {43}\n}\n\n@article{ citeulike:6544583,\n abstract = {This study examines Dublin Core (DC) metadata semantics drawn from the perspectives and experiences of cataloguing and metadata professionals. The study ascertains the extent of difficulty in applying the DC metadata elements encountered by these professionals and examines factors engendering such difficulties during the metadata application process. Comments drawn from the survey participants (n = 141) show that conceptual ambiguities (41\\%) and semantic overlaps (45\\%) of the surveyed DC metadata elements are the most frequently cited factors causing difficulty and confusion, in turn leading to variant interpretations of DC metadata elements. This has the potential to bring forth inconsistent and inaccurate applications and implementation of the DC standard across institutions which can directly affect semantic interoperability across digital repositories. The high degree of difficulty (55.3\\%) engendered by the Relation field indicates that further examination of this element is needed. 10.1177/0165551509337871},\n author = {Jungran Park and Eric Childress},\n citeulike-article-id = {6544583},\n citeulike-linkout-0 = {http://dx.doi.org/10.1177/0165551509337871},\n citeulike-linkout-1 = {http://jis.sagepub.com/cgi/content/abstract/35/6/727},\n day = {1},\n doi = {10.1177/0165551509337871},\n journal = {Journal of Information Science},\n keyword = {metadata, semantic},\n link = {http://dx.doi.org/10.1177/0165551509337871},\n month = {December},\n number = {6},\n pages = {727--739},\n posted-at = {2010-01-15 16:52:46},\n priority = {0},\n title = {Dublin Core metadata semantics: an analysis of the perspectives of information professionals},\n volume = {35},\n year = {2009}\n}\n\n@article{ citeulike:6544603,\n author = {Elizabeth D. Liddy},\n citeulike-article-id = {6544603},\n citeulike-linkout-0 = {http://dx.doi.org/DOI:%2010.1016/0306-4573(91)90031-G},\n citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6VC8-469PG60-X/2/e7c57a99a38b2760902b9b5315edc224},\n doi = {DOI:%2010.1016/0306-4573(91)90031-G},\n journal = {Information Processing \\& Management},\n link = {http://dx.doi.org/DOI:%2010.1016/0306-4573(91)90031-G},\n number = {1},\n pages = {55--81},\n posted-at = {2010-01-15 17:03:51},\n priority = {2},\n title = {The discourse-level structure of empirical abstracts: an exploratory study},\n volume = {27}\n}\n\n@article{ citeulike:6544607,\n address = {New York, NY, USA},\n author = {Alenka \\v{S}auperl and Janko Klasinc and Simona Lu\\v{z}ar},\n citeulike-article-id = {6544607},\n citeulike-linkout-0 = {http://dx.doi.org/http://dx.doi.org/10.1002/asi.v59:9},\n doi = {http://dx.doi.org/10.1002/asi.v59:9},\n journal = {Journal of the American Society for Information Science and Technology},\n link = {http://dx.doi.org/http://dx.doi.org/10.1002/asi.v59:9},\n number = {9},\n pages = {1420--1432},\n posted-at = {2010-01-15 17:07:04},\n priority = {2},\n publisher = {John Wiley \\& Sons, Inc.},\n title = {Components of abstracts: Logical structure of scholarly abstracts in pharmacology, sociology, and linguistics and literature},\n volume = {59}\n}\n\n@inproceedings{ citeulike:6544669,\n author = {Jane Greenberg and Maria C. Pattuelli and Bijan Parsia and W. Davenport Robertson},\n booktitle = {DCMI '01: Proceedings of the International Conference on Dublin Core and Metadata Applications 2001},\n citeulike-article-id = {6544669},\n keyword = {metadata},\n pages = {38--46},\n posted-at = {2010-01-15 17:22:41},\n priority = {2},\n publisher = {National Institute of Informatics, Tokyo, Japan},\n title = {Author-generated Dublin Core Metadata for Web Resources: A Baseline Study in an Organization}\n}\n\n@article{ citeulike:6545091,\n abstract = {There has been notably little convergence between information organization and information use studies. A framework for explicating the contextual interplay of information interactions and infrastructures of information, and more specifically the interface of information work and knowledge organization systems, is proposed. The theoretical foundations of the framework are based on systems theory and ecological approach. It is suggested that the interplay of information use and information infrastructures may be conceptualized as a systemic interaction, which is driven by the simultaneous influence of human activity related warrants and infrastructural affordances and constraints. The model provides an instrument that explicates the interplay of human information use and information infrastructures. 10.1177/0165551509336705},\n author = {Isto Huvila},\n citeulike-article-id = {6545091},\n citeulike-linkout-0 = {http://dx.doi.org/10.1177/0165551509336705},\n citeulike-linkout-1 = {http://jis.sagepub.com/cgi/content/abstract/35/6/695},\n day = {1},\n doi = {10.1177/0165551509336705},\n journal = {Journal of Information Science},\n link = {http://dx.doi.org/10.1177/0165551509336705},\n month = {December},\n number = {6},\n pages = {695--708},\n posted-at = {2010-01-15 19:34:11},\n priority = {2},\n title = {Ecological framework of information interactions and information infrastructures},\n volume = {35}\n}\n\n@phdthesis{ citeulike:6545103,\n author = {Setch {Van Hooland}},\n citeulike-article-id = {6545103},\n keyword = {cultural\\_heritage, metadata, metadata\\_quality},\n organization = {University Libre de Bruxelles},\n posted-at = {2010-01-15 19:51:29},\n priority = {2},\n title = {Metadata Quality in the Cultural Heritage Sector: Stakes, Problems and Solutions}\n}\n\n@article{ citeulike:6545132,\n abstract = {The objectives of the study were to conduct a series of observations and experiments under as real-life situ-ation as possible related to: (1) user context of questions in information retrieval; (2) the structure and classi-fication of questions; (3) cognitive traits and decision making of searchers; and (4) different searches of the same question. The study is presented in three parts: Part I presents the background of the study and de-scribes the models, measures, methods, procedures and statistical analyses used. Part II is devoted to results related to users, questions and effectiveness measures, and Part III to results related to searchers, searches and overlap studies. A concluding summary of all results is presented in Part III.},\n author = {Tefko Saracevic and Paul Kantor},\n citeulike-article-id = {6545132},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.87.5184},\n journal = {Journal of the American Society for Information Science},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.87.5184},\n pages = {197--216},\n posted-at = {2010-01-15 20:06:12},\n priority = {2},\n title = {A study of information seeking and retrieving. III. searchers, searches, overlap},\n volume = {39}\n}\n\n@article{ citeulike:6545138,\n abstract = {The objectives of the study were to conduct a series of observations and experiments under as real-life a situa-tion as possible related to: (i) user context of questions in information retrieval; (ii) the structure and classi-fication of questions; (iii) cognitive traits and decision making of searchers; and (iv) different searches of the same question. The study is presented in three parts: Part I presents the background ot the study and de-scribes the models, measures, methods, procedures, and statistical analyses used. Part II is devoted to results related to users, questions, and effectiveness measures, and Part III to results related to searchers, searches, and overlap studies. A concluding summary of all results is presented in Part III. introduction Problem, Motivation, Significance Users and their questions are fundamental to all kinds of information systems, and human decisions and human-system interactions are by far the most important variables in processes dealing with searching for and retrieval of in-formation. These statements are true to the point of being trite. Nevertheless, it is nothing but short of amazing how relatively little knowledge and understanding in a scientific sense we have about these factors. Information retrieval},\n author = {Tefko Saracevic and Paul Kantor and Alice Y. Chamis and Donna Trivison},\n citeulike-article-id = {6545138},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.94.4923},\n journal = {Journal of the American Society for Information Science},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.94.4923},\n pages = {161--176},\n posted-at = {2010-01-15 20:08:07},\n priority = {2},\n title = {A study of information seeking and retrieving. I. Background and methodology},\n volume = {39}\n}\n\n@article{ citeulike:6545140,\n abstract = {The objectives of the study were to conduct a series of observations and experiments under as real-life a situ-ation as possible related to: (1) user context of questions in information retrieval; (2) the structure and classi-fication of questions; (3) cognitive traits and decision making of searchers; and (4) different searches of the same question. The study is presented in three parts: Part I presents the background of the study and de-scribes the models, measures, methods, procedures and statistical analyses used. Part II is devoted to results related to users, questions and effectiveness measures, and Part Ill to results related to searchers, searches and overlap studies. A concluding summary of all results is presented in Part ill. Summary of the Study This is a second article in a series of three, reporting on a study of information seeking and retrieving. The first dealt with the methodological aspects describing the aim, objec-tives and approach, related works, and models, measures and procedures used, including references appropriate for the study as a whole [ 11. This second part concentrates on results connected with users, questions, and effectiveness measures. The third part concentrates on results connected with searchers, searches, and overlap studies. A Final Re-port together with appendices was deposited with ERIC and NTIS [2]; it contains the details of the study with emphasis on procedures and presentation of ” raw ” data. A summary of methods used in the study is provided here, so that a reader},\n author = {Tefko Saracevic and Paul Kantor},\n citeulike-article-id = {6545140},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.119.6060},\n journal = {Journal of the American Society for Information Science},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.119.6060},\n pages = {177--196},\n posted-at = {2010-01-15 20:09:19},\n priority = {2},\n title = {A study of information seeking and retrieving. II. Users, questions, and effectiveness},\n volume = {39}\n}\n\n@article{ citeulike:6545152,\n author = {Pranas Zunde and Margaret E. Dexter},\n citeulike-article-id = {6545152},\n journal = {American Documentation},\n month = {July},\n pages = {259--267},\n posted-at = {2010-01-15 20:13:40},\n priority = {2},\n title = {Indexing Consistency and Quality}\n}\n\n@inproceedings{ citeulike:6545158,\n author = {Thomas Margaritopoulos and Merkourios Margaritopoulos and Ioannis Mavridis and Athanasios Manitsaris},\n booktitle = {DCMI '08: Proceedings of the 2008 International Conference on Dublin Core and Metadata Applications},\n citeulike-article-id = {6545158},\n keyword = {file-import-10-01-15},\n location = {Berlin, Germany},\n pages = {104--113},\n posted-at = {2010-01-15 20:17:08},\n priority = {2},\n publisher = {Dublin Core Metadata Initiative},\n title = {A conceptual framework for metadata quality assessment},\n year = {2008}\n}\n\n@article{ citeulike:6545178,\n abstract = {The study consisted of two interrelated parts: (1) a quality analysis of the Chinese-language records in the OCLC database, with emphasis on identifying errors in member-contributed records; and (2) the development of a rule-based data validation system for quality control of Chinese-language records in the OCLC database, with emphasis on establishing a set of production rules for such a system. One thousand three hundred six member-contributed Chinese records were randomly selected from the OCLC database and were examined by the researcher. Commonly occurring errors were identified and were categorized into three classes: format errors, content deficiency and inconsistency errors, and typographical errors of editing and inputting. The relationship between the number of times a record had been enhanced and errors still occurring in it was also studied.},\n author = {Lei Zeng},\n citeulike-article-id = {6545178},\n citeulike-linkout-0 = {http://dx.doi.org/10.1300/J104v16n04\\\\_03},\n doi = {10.1300/J104v16n04\\_03},\n journal = {Cataloging \\& Classification Quarterly},\n keyword = {quality},\n link = {http://dx.doi.org/10.1300/J104v16n04_03},\n number = {4},\n pages = {25--66},\n posted-at = {2010-01-15 20:33:50},\n priority = {0},\n publisher = {Routledge},\n title = {Quality Control of Chinese-Language Records Using a Rule-Based Data Validation System - Part 1 -- An Evaluation of the Quality of Chinese-Language Records in the OCLC OLUC Database},\n volume = {16}\n}\n\n@article{ citeulike:6545182,\n abstract = {The problem addressed by this two-part study is to evaluate the quality of Chinese records in the OCLC database and to determine the potential of a set of production rules for a rule-based data validation system lo support quality control of the Chinese records. The second part of the study emphasizes establishing pro- duction rules for such a system. Based on the results of error anal- ysis, a set of production rules were developed and tested, focusing on improving completeness, consistency, and correctness of a rec- ord. The rules covered 11 of the total 19 types of errors. At least 65\\% , of the errors occurring in the investigated sample records could be detected automatically by applying the production rules.},\n author = {Lei Zeng},\n citeulike-article-id = {6545182},\n citeulike-linkout-0 = {http://dx.doi.org/10.1300/J104v18n01\\\\_02},\n doi = {10.1300/J104v18n01\\_02},\n journal = {Cataloging \\& Classification Quarterly},\n keyword = {quality, quality\\_metrics},\n link = {http://dx.doi.org/10.1300/J104v18n01_02},\n number = {1},\n pages = {3--26},\n posted-at = {2010-01-15 20:37:07},\n priority = {2},\n publisher = {Routledge},\n title = {Quality Control of Chinese-Language Records Using a Rule-Based Data Validation System-Part 2 -- A Study of a Rule-Based Data Validation System for Online Chinese Cataloging},\n volume = {18}\n}\n\n@article{ citeulike:6545194,\n abstract = {Web documents are available in various forms, most of which do not carry additional semantics. This paper presents a model for general document metadata extraction. The model, which combines segmentation by keywords and pattern matching techniques, was implemented using PHP, MySQL, JavaScript and HTML. The system was tested with 40 randomly selected PDF documents (mainly theses). An evaluation of the system was done using standard criteria measures namely precision, recall, accuracy and F-measure. The results show that the model is relatively effective for the task of metadata extraction, especially for theses and dissertations. A combination of machine learning with these rule-based methods will be explored in the future for better results. 10.1177/0165551509105195},\n author = {Bolanle {Adefowoke Ojokoh} and Olumide {Sunday Adewale} and Samuel {Oluwole Falaki}},\n citeulike-article-id = {6545194},\n citeulike-linkout-0 = {http://dx.doi.org/10.1177/0165551509105195},\n citeulike-linkout-1 = {http://jis.sagepub.com/cgi/content/abstract/35/5/563},\n day = {1},\n doi = {10.1177/0165551509105195},\n journal = {Journal of Information Science},\n link = {http://dx.doi.org/10.1177/0165551509105195},\n month = {October},\n number = {5},\n pages = {563--570},\n posted-at = {2010-01-15 20:48:09},\n priority = {2},\n title = {Automated document metadata extraction},\n volume = {35}\n}\n\n@article{ citeulike:6548831,\n abstract = {Purpose -- To report the results of the 2005 {CARL} survey of institutional repositories {(IRs)} and discuss some of the challenges of implementing {IRs} in Canada. Design/methodology/approach -- This takes the form of a survey questionnaire. Findings -- There are a number of important issues confronting implementers of institutional repositories. Most of these issues are not insurmountable,but, to be properly addressed will require collaboration amongst implementers and resources. Research limitations/implications -- The findings issues identified through the survey contribute to the workplan of the {CARL} Institutional Repositories Project. Originality/value -- The paper presents an up to date account of the state of institutional repositories in Canada.},\n author = {Kathleen Shearer},\n citeulike-article-id = {6548831},\n citeulike-linkout-0 = {http://dx.doi.org/10.1108/07378830610669547},\n citeulike-linkout-1 = {http://www.emeraldinsight.com/10.1108/07378830610669547},\n doi = {10.1108/07378830610669547},\n journal = {Library Hi Tech},\n keyword = {canada, digital, file-import-10-01-16, libraries},\n link = {http://dx.doi.org/10.1108/07378830610669547},\n number = {2},\n pages = {165--172},\n posted-at = {2010-01-16 01:33:22},\n priority = {2},\n title = {The {CARL} institutional repositories project: A collaborative approach to addressing the challenges of {IRs} in Canada},\n volume = {24}\n}\n\n@article{ citeulike:6548833,\n abstract = {Purpose -- To report on the University of Toronto's implementation of an institutional repository. Design/methodology/approach -- Describe decision making process. A range of qualitative research methods were used to solicit early adopter and library concerns. Findings were then used to guide implementation. Findings -- Provides the rational behind decisions made. Argues that modified qualitative research methods may be useful to new library projects. Research limitations/implications -- The report is specific to an institution. Practical implications -- Prioritizing actions, focusing on faculty and leveraging resources, notably student assistants is key. Originality/value -- This paper provides practical information and a model which may be useful for others implementing repository services or other emerging technologies.},\n author = {Rea Devakos},\n citeulike-article-id = {6548833},\n citeulike-linkout-0 = {http://dx.doi.org/10.1108/07378830610669556},\n citeulike-linkout-1 = {http://www.emeraldinsight.com/10.1108/07378830610669556},\n doi = {10.1108/07378830610669556},\n journal = {Library Hi Tech},\n keyword = {academic, digital, file-import-10-01-16, libraries, qualitative, research},\n link = {http://dx.doi.org/10.1108/07378830610669556},\n number = {2},\n pages = {173--182},\n posted-at = {2010-01-16 01:34:41},\n priority = {2},\n title = {Towards user responsive institutional repositories: a case study},\n volume = {24}\n}\n\n@article{ citeulike:6548921,\n abstract = {Purpose -- The purpose of this paper is to discuss issues associated with open access {(OA)} to electronic theses and dissertations {(ETDs)} and to describe the University of Waterloo E-thesis Project and its partnerships with Theses Canada and the Networked Digital Library of Theses and Dissertations. Design/methodology/approach -- {UW} E-thesis Project decisions on issues associated with electronic submission and {OA} are presented. Partnerships with Theses Canada and the Networked Digital Library of Theses and Dissertations are described and the goals and activities of these organizations are outlined. Findings -- Author-created metadata form the {UW} E-theses searchable database of records that link to theses in full text. The metadata are {OAI} compliant and are harvested by Theses Canada and the {ETD} Union Catalog. The E-theses Project supports authors' rights while minimizing access restrictions and encourages innovations while respecting the value of gradually evolving thesis standards and traditions. The success of the {UW} E-thesis Project illustrates that progress can be made toward the {OA} paradigm for theses and dissertations while upholding perennial values. Collaborations with like-minded organizations support and advance these goals. Originality/value -- Academic librarians and graduate studies officers will find this e-thesis project description and this discussion of issues relevant to planning and maintaining electronic thesis submission and access systems at their own universities. The descriptions of the benefits of the partnerships may prompt readers to make similar connections themselves.},\n author = {Christine Jewell and William Oldfield and Sharon Reeves},\n citeulike-article-id = {6548921},\n citeulike-linkout-0 = {http://dx.doi.org/10.1108/07378830610669565},\n citeulike-linkout-1 = {http://www.emeraldinsight.com/10.1108/07378830610669565},\n doi = {10.1108/07378830610669565},\n journal = {Library Hi Tech},\n keyword = {canada, delivery, digital, document, electronic, file-import-10-01-16, libraries, theses},\n link = {http://dx.doi.org/10.1108/07378830610669565},\n number = {2},\n pages = {183--196},\n posted-at = {2010-01-16 01:43:14},\n priority = {2},\n title = {University of Waterloo electronic theses: issues and partnerships},\n volume = {24}\n}\n\n@article{ citeulike:6548923,\n abstract = {Purpose -- This paper proposes indicators for measuring the success of institutional repositories based on their demonstrated integration with other research initiatives and provides a snapshot of the current state of selected institutional repositories in Canada through a review of their web presence and their integration with university library and research pages. Design/methodology/approach -- Using the proposed indicators, an examination of the web sites of selected Canadian universities who are participating in the Canadian Association of Research Libraries Institutional Repository project was undertaken. Findings -- Institutional repositories are growing in Canada and that the Canadian {IR} community is on the way to the proposed model future -- integration with existing university research practices. Originality/value -- Indicators such as those proposed in the paper can provide a basic framework for evaluating {IR} projects and highlight areas where the library can generate additional support for these worthwhile projects.},\n author = {Mary Westell},\n citeulike-article-id = {6548923},\n citeulike-linkout-0 = {http://dx.doi.org/10.1108/07378830610669583},\n citeulike-linkout-1 = {http://www.emeraldinsight.com/10.1108/07378830610669583},\n doi = {10.1108/07378830610669583},\n journal = {Library Hi Tech},\n keyword = {canada, critical, digital, factors, file-import-10-01-16, libraries, research, success},\n link = {http://dx.doi.org/10.1108/07378830610669583},\n number = {2},\n pages = {211--226},\n posted-at = {2010-01-16 01:44:35},\n priority = {2},\n title = {Institutional repositories: proposed indicators of success},\n volume = {24}\n}\n\n@inproceedings{ citeulike:6549002,\n abstract = {From an architectural perspective, there is no essential distinction between data and metadata. Both can be represented in distributed active relationships {(DARs),} which are an extension of the Warwick framework {(C.} Lagoze et al., 1996). The {DAR} model is a powerful way to express relationships between networked resources and to allow such relationships to be dynamically downloadable and executable},\n author = {R. Daniel and C. Lagoze and S. D. Payette},\n booktitle = {Research and Technology Advances in Digital Libraries, 1998. ADL 98. Proceedings. IEEE International Forum on},\n citeulike-article-id = {6549002},\n citeulike-linkout-0 = {http://dx.doi.org/10.1109/ADL.1998.670428},\n doi = {10.1109/ADL.1998.670428},\n keyword = {active, architecture, dar, data, databases, digital, distributed, downloadable, dynamically, executable, file-import-10-01-16, framework, information, libraries, metadata, networked, relationships, resource, retrieval, structures, systems, warwick},\n link = {http://dx.doi.org/10.1109/ADL.1998.670428},\n pages = {276--288},\n posted-at = {2010-01-16 01:54:34},\n priority = {2},\n title = {A metadata architecture for digital libraries}\n}\n\n@article{ citeulike:6551045,\n abstract = {A survey on metadata conducted at the end of 2007 received over 400 answers from 49 countries all over the world. It helped the authors to identify major issues and concerns regarding metadata that should be addressed in the IFLA Guidelines for Digital Libraries. The questionnaire included a question of the roles respondents may have, and five questions of the major concerns in any project that relates to metadata, regarding design and planning of digital projects, element set standards, data contents in a record, authority files and controlled vocabularies, and metadata encoding. Findings from the survey are reported and a workflow chart is included in this paper.},\n author = {Marcia L. Zeng and Jaesun Lee and Allene F. Hayes},\n citeulike-article-id = {6551045},\n citeulike-linkout-0 = {http://dx.doi.org/10.1080/19386380903405074},\n doi = {10.1080/19386380903405074},\n journal = {Journal of Library Metadata},\n keyword = {digital\\_library, metadata},\n link = {http://dx.doi.org/10.1080/19386380903405074},\n number = {3},\n pages = {173--193},\n posted-at = {2010-01-16 16:55:58},\n priority = {2},\n publisher = {Routledge},\n title = {Metadata Decisions for Digital Libraries: A Survey Report},\n volume = {9}\n}\n\n@article{ citeulike:6551053,\n abstract = {Digital data repositories ought to support immediate operational needs and long-term project goals. This paper presents the Dryad repository's metadata best practice balancing of these two needs. The paper reviews background work exploring the meaning of science, characterizing data, and highlighting data curation metadata challenges. The Dryad repository is introduced, and the initiative's metadata best practice and underlying rationales are described. Dryad's metadata approach includes two prongs: one addressing the long-term goal to align with the Semantic Web via a metadata application profile; and another addressing the immediate need to make content available in DSpace via an extensible markup language (XML) schema. The conclusion summarizes limitations and advantages of the two prongs underlying Dryad's metadata effort.},\n author = {Jane Greenberg and Hollie C. White and Sarah Carrier and Ryan Scherle},\n citeulike-article-id = {6551053},\n citeulike-linkout-0 = {http://dx.doi.org/10.1080/19386380903405090},\n doi = {10.1080/19386380903405090},\n journal = {Journal of Library Metadata},\n keyword = {metadata, repository},\n link = {http://dx.doi.org/10.1080/19386380903405090},\n number = {3},\n pages = {194--212},\n posted-at = {2010-01-16 17:02:49},\n priority = {2},\n publisher = {Routledge},\n title = {A Metadata Best Practice for a Scientific Data Repository},\n volume = {9}\n}\n\n@article{ citeulike:6551058,\n abstract = {The University of New Mexico will mandate in 2009 that theses and dissertations be submitted in electronic form as the copy of record. These documents will reside in the university's digital repository, operated on a DSpace platform. This article reviews practices for thesis and dissertation metadata creation with a focus on DSpace instances, best practice recommendations for author-submitted metadata, recommendations for subject analysis, and training for metadata practitioners. The article recommends processes for author submission, metadata quality control and enhancement, and crosswalking of the metadata to the library's catalog to maximize discovery.},\n author = {Rebecca L. Lubas},\n citeulike-article-id = {6551058},\n citeulike-linkout-0 = {http://dx.doi.org/10.1080/19386380903405165},\n doi = {10.1080/19386380903405165},\n journal = {Journal of Library Metadata},\n keyword = {etd, metadata},\n link = {http://dx.doi.org/10.1080/19386380903405165},\n number = {3},\n pages = {252--263},\n posted-at = {2010-01-16 17:03:40},\n priority = {2},\n publisher = {Routledge},\n title = {Defining Best Practices in Electronic Thesis and Dissertation Metadata},\n volume = {9}\n}\n\n@article{ citeulike:6551063,\n abstract = {This study assesses the current metadata practices and trends in Association of Research Libraries (ARL) libraries, based on the survey Metadata conducted in spring 2007 (SPEC Kit 298: Metadata), a collaborative effort with the staff at the ARL. The survey investigates how metadata has been implemented in ARL member libraries: what kinds of projects or initiatives have been undertaken, what types of digital objects are associated with metadata, who are creating metadata, what schemas and tools are used to create and manage metadata, and the organizational changes and challenges resulting from the adoption of metadata in the libraries. The author summarizes her observations of the findings and the main themes that emerged from the metadata practices in libraries. She assesses the changing context of metadata creation and management and the evolution of metadata workflow and best practices in libraries. The author also discusses the roles and responsibilities of metadata professionals and the implications of metadata practices for the library and information community.},\n author = {Jin Ma},\n citeulike-article-id = {6551063},\n citeulike-linkout-0 = {http://dx.doi.org/10.1080/19386380903094977},\n doi = {10.1080/19386380903094977},\n journal = {Journal of Library Metadata},\n keyword = {metadata, survey},\n link = {http://dx.doi.org/10.1080/19386380903094977},\n number = {1},\n pages = {1--14},\n posted-at = {2010-01-16 17:06:50},\n priority = {2},\n publisher = {Routledge},\n title = {Metadata in ARL Libraries: A Survey of Metadata Practices},\n volume = {9}\n}\n\n@article{ citeulike:6551067,\n abstract = {This article will focus on how two different metadata harvestersOAIster and the Online Computer Library Center's (OCLC) WorldCattransform and present Dublin Core metadata extracted from CONTENTdm. It offers an examination, in plain language, of what two service providers do to metadata once they are harvested, and, in a case study, shows examples of how specific records display in both the local and aggregated interfaces. By helping metadata creators understand what happens to their metadata as it is harvested and transformed, this article aims to assist them in designing their metadata to be intelligible and useful to end-users across platforms.},\n author = {Amalia Beisler and Glee Willis},\n citeulike-article-id = {6551067},\n citeulike-linkout-0 = {http://dx.doi.org/10.1080/19386380903095099},\n doi = {10.1080/19386380903095099},\n journal = {Journal of Library Metadata},\n keyword = {metadata, oai},\n link = {http://dx.doi.org/10.1080/19386380903095099},\n number = {1},\n pages = {65--97},\n posted-at = {2010-01-16 17:08:22},\n priority = {2},\n publisher = {Routledge},\n title = {Beyond Theory: Preparing Dublin Core Metadata for OAI-PMH Harvesting},\n volume = {9},\n year = {2009}\n}\n\n@article{ citeulike:6554105,\n author = {Dimitrios A. Koutsomitropoulos and Georgia D. Solomou and Theodore S. Papatheodorou},\n citeulike-article-id = {6554105},\n citeulike-linkout-0 = {http://journals.tdl.org/jodi/article/viewArticle/693},\n comment = {Digital collections often foster a large number of digital resources that need to be efficiently managed, described and disseminated. Metadata play a key role in these tasks as they offer the basis upon which more advanced services can be built. However, it is not always the case that such collections' metadata expose explicit or even well-structured semantics. Ways to bridge this \"semantic gap\" are increasingly being sought, as our review of the current state-of-the-art reveals. Most importantly though, in this paper we comment on two well-known metadata standards, popular in cultural heritage applications, namely {CIDOC-CRM} and Dublin Core; as diverse their scope may be, we nevertheless show how applications can benefit from a transition to explicit semantic structures in these domains, in a way as painless as possible and conformant to Semantic Web standards. We conclude by presenting a concrete, prototype implementation that serves as a proof-of-concept about the ideas argued for.},\n journal = {Journal of Digital Information},\n keyword = {file-import-10-01-17},\n link = {http://journals.tdl.org/jodi/article/viewArticle/693},\n number = {6},\n posted-at = {2010-01-17 22:38:33},\n priority = {2},\n title = {Metadata and Semantics in Digital Object Collections: A Case-Study on CIDOC-CRM and Dublin Core and a Prototype Implementation},\n volume = {10},\n year = {2009}\n}\n\n@article{ citeulike:6567098,\n abstract = {Metadata can be used to precisely represent data semantics. It can also serve to improve data sharing and exchange. Because the various types of metadata are created in different ways, they can suffer from a problem of inconsistency. Recently, metadata gateway methods have been researched to solve this problem. However, the performance of the existing approaches based on metadata schemas is poor and their maintenance (adaptation of metadata changes) is time consuming. In this paper, a novel message conversion system is proposed, which functions by separating the heterogeneous mapping information from the mapping rules of the metadata, in order to overcome the drawbacks of the existing metadata gateway methods. The proposed system controls the standardized data elements dynamically based on the Metadata Registry (MDR), which is one of the most important elements of the ISO/IEC 11179 standard. The problems associated with adding supplementary metadata are resolved, since the standard provides for incorporating additional data elements created in the future. MSDL is defined as a protocol which can be used for exchanging messages between heterogeneous systems, and which ensures that all of the systems have their own independent metadata schemas. 10.1177/0165551505055403},\n author = {Dongwon Jeong and Peter H. In and Fran Jarnjak and Young-Gab Kim and Doo-Kwon Baik},\n citeulike-article-id = {6567098},\n citeulike-linkout-0 = {http://dx.doi.org/10.1177/0165551505055403},\n citeulike-linkout-1 = {http://jis.sagepub.com/cgi/content/abstract/31/5/394},\n day = {1},\n doi = {10.1177/0165551505055403},\n journal = {Journal of Information Science},\n keyword = {metadata\\_repository, metadata\\_semantics},\n link = {http://dx.doi.org/10.1177/0165551505055403},\n month = {October},\n number = {5},\n pages = {394--406},\n posted-at = {2010-01-20 15:21:39},\n priority = {2},\n title = {A message conversion system, XML-based metadata semantics description language and metadata repository},\n volume = {31}\n}\n\n@article{ citeulike:6588726,\n abstract = {With the proliferation of Web 2.0 technologies, there is an expanded opportunity for individuals to get involved in information exchange. In this study, the sustainability of a virtual community for teachers and educators were investigated. The research model borrows the key concepts from the IS continuance model, social influence theory, the uses and gratifications paradigm, and relationship marketing to explain user intention to continue using a virtual community, as well as intention to recommend the community to others. Satisfaction, commitment, group norms are found to have significant impacts on intention to continue using and intention to recommend. Among the three factors, satisfaction has the highest impact on behavioral intentions. Individual-related factors (purposive value and self-discovery) are found to have significant impacts on user satisfaction, while social-related factors are more important in determining commitment and group norms. The results of this study provide important implications for both research and practice. 10.1177/0165551508099088},\n author = {Christy M. K. Cheung and Matthew K. O. Lee},\n citeulike-article-id = {6588726},\n citeulike-linkout-0 = {http://dx.doi.org/10.1177/0165551508099088},\n citeulike-linkout-1 = {http://jis.sagepub.com/cgi/content/abstract/35/3/279},\n day = {1},\n doi = {10.1177/0165551508099088},\n journal = {Journal of Information Science},\n link = {http://dx.doi.org/10.1177/0165551508099088},\n month = {June},\n number = {3},\n pages = {279--298},\n posted-at = {2010-01-25 19:07:49},\n priority = {2},\n title = {Understanding the sustainability of a virtual community: model development and empirical test},\n volume = {35}\n}\n\n@article{ citeulike:6604311,\n abstract = {The X-Map system for automated semantic correlation between multiple schemas represents a novel perspective for mediating XML data interoperability between multiple heterogeneous systems. Instead of using time consuming data-domain modeling or other pre-constructed knowledge about the systems\\&\\#039; data-domain, X-Map relies on three techniques to do its job, none of which require pre-construction of anything: relevant definition of equivalence and other classes of relations, speculative evaluation of relations between data-domains, and a regenerative association engine to reevaluate speculations. Restriction to valid XML data also gives X-Map some advantage, including well-formedness, parsing, and data element identification. Essentially, X-Map uses the definition of equivalence to plant seeds of possible correlation between schema elements, speculates on the relation\\&\\#039;s correctness, then continuously re-evaluates the correctness of the speculative relations when given additional information from newly introduced schemas. In e\\#ect, X-Map generates and harbors a large growing body of knowledge between the elements of the many schemas that it encounters. Furthermore, this knowledge is store in valid XML format (XLink linkbase and standard valid XML), enabling other XML-compliant applications to perform related mediation tasks such as data transformation and translation.},\n author = {David Wang and Amar Gupta and Arthur C. Smith},\n citeulike-article-id = {6604311},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.8744},\n keyword = {interoperability, schema, semantic},\n link = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.8744},\n posted-at = {2010-01-29 16:23:55},\n priority = {2},\n title = {Automated Semantic Correlation between Multiple Schema for Information Exchange},\n year = {2000}\n}\n\n@article{ citeulike:6654507,\n abstract = {Websites that provide content creation and sharing features have become quite popular recently. These sites allow users to categorize and browse content using tags' or free-text keyword topics. Since users contribute and tag social media content across a variety of social web platforms, creating new knowledge from distributed tag data has become a matter of performing various tasks, including publishing, aggregating, integrating, and republishing tag data. However, there are a number of issues in relation to data sharing and interoperability when processing tag data across heterogeneous tagging platforms. In this paper we introduce a semantic tag model that aims to explicitly offer the necessary structure, semantics and relationships between tags. This approach provides an improved opportunity for representing tag data in the form of reusable constructs at a semantic level. We also demonstrate a prototype that consumes and makes use of shared tag metadata across heterogeneous sources. 10.1177/0165551509346785},\n author = {Hak-Lae Kim and Stefan Decker and John G. Breslin},\n citeulike-article-id = {6654507},\n citeulike-linkout-0 = {http://dx.doi.org/10.1177/0165551509346785},\n citeulike-linkout-1 = {http://jis.sagepub.com/cgi/content/abstract/36/1/57},\n day = {1},\n doi = {10.1177/0165551509346785},\n journal = {Journal of Information Science},\n keyword = {semantics},\n link = {http://dx.doi.org/10.1177/0165551509346785},\n month = {February},\n number = {1},\n pages = {57--72},\n posted-at = {2010-02-11 16:44:59},\n priority = {5},\n title = {Representing and sharing folksonomies with semantics},\n volume = {36},\n year = {2010}\n}\n\n@article{ citeulike:6854365,\n abstract = {In current library practice, trained human experts usually carry out document cataloguing and indexing based on a manual approach. With the explosive growth in the number of electronic documents available on the Internet and digital libraries, it is increasingly difficult for library practitioners to categorize both electronic documents and traditional library materials using just a manual approach. To improve the effectiveness and efficiency of document categorization at the library setting, more in-depth studies of using automatic document classification methods to categorize library items are required. Machine learning research has advanced rapidly in recent years. However, applying machine learning techniques to improve library practice is still a relatively unexplored area. This paper illustrates the design and development of a machine learning based automatic document classification system to alleviate the manual categorization problem encountered within the library setting. Two supervised machine learning algorithms have been tested. Our empirical tests show that supervised machine learning algorithms in general, and the k-nearest neighbours (KNN) algorithm in particular, can be used to develop an effective document classification system to enhance current library practice. Moreover, some concrete recommendations regarding how to practically apply the KNN algorithm to develop automatic document classification in a library setting are made. To our best knowledge, this is the first in-depth study of applying the KNN algorithm to automatic document classification based on the widely used LCC classification scheme adopted by many large libraries. 10.1177/0165551507082592},\n author = {Joanna Y. Pong and Ron C. Kwok and Raymond Y. Lau and Jin-Xing Hao and Percy C. Wong},\n citeulike-article-id = {6854365},\n citeulike-linkout-0 = {http://dx.doi.org/10.1177/0165551507082592},\n citeulike-linkout-1 = {http://jis.sagepub.com/cgi/content/abstract/34/2/213},\n day = {1},\n doi = {10.1177/0165551507082592},\n journal = {Journal of Information Science},\n link = {http://dx.doi.org/10.1177/0165551507082592},\n month = {April},\n number = {2},\n pages = {213--230},\n posted-at = {2010-03-15 20:21:39},\n priority = {2},\n title = {A comparative study of two automatic document classification methods in a library setting},\n volume = {34}\n}\n\n@book{ citeulike:687659,\n author = {Diane I. Hillman and Elaine L. Westbrooks},\n citeulike-article-id = {687659},\n howpublished = {Paperback},\n isbn = {0838908829},\n keyword = {metadata},\n posted-at = {2009-06-30 20:29:52},\n priority = {2},\n publisher = {American Library Association},\n title = {Metadata in Practice},\n year = {2004}\n}\n\n@article{ citeulike:6994468,\n abstract = {In this article, an approach to personal information management is described that is based on Semantic},\n author = {William I. Grosky and Farshad Fotouhi and Bodo H{\\\"u}semann Informationsfabrik Gmbh M{\\\"u}nster},\n citeulike-article-id = {6994468},\n citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.113.9128},\n keyword = {ontology, ontology\\_construction, ontomedia},\n posted-at = {2010-04-10 03:50:27},\n priority = {2},\n title = {Table of Contents 1 OntoMedia—Semantic Multimedia Metadata Integration and Organization}\n}\n\n@article{ citeulike:7057306,\n abstract = {A new approach to scientometric indicators which is based on frequency distribution characteristics is presented. The pub lication productivity of ten major OECD countries during the 1981-1985 period is studied. A stochastic \"cumulative ad vantage\" process having a Waring-type stationary limit distri bution is assumed to underlie the publication process. This model makes it possible to estimate such indicators as the \"Publication Potential\" and the \"Cumulative Advantage Coef ficient\" which indicate the number of potential and of factual authors and the effect of the \"success-breeds-success\" phenom enon, respectively. A discussion of the publication behaviour of the scientific elite based on indicators of the distribution tail concludes the comparative evaluation. 10.1177/016555159001600107},\n author = {T. Braun and W. Glanzel and A. Schubert},\n citeulike-article-id = {7057306},\n citeulike-linkout-0 = {http://dx.doi.org/10.1177/016555159001600107},\n citeulike-linkout-1 = {http://jis.sagepub.com/cgi/content/abstract/16/1/37},\n day = {1},\n doi = {10.1177/016555159001600107},\n journal = {Journal of Information Science},\n keyword = {frequency\\_distribution, lotka},\n link = {http://dx.doi.org/10.1177/016555159001600107},\n month = {January},\n number = {1},\n pages = {37--44},\n posted-at = {2010-04-22 09:16:52},\n priority = {2},\n title = {Publication productivity: from frequency distributions to scientometric indicators},\n volume = {16}\n}\n\n@book{ citeulike:813763,\n abstract = {{This fully revised and updated second edition of <b>Understanding Digital Libraries</b> focuses on the challenges faced by both librarians and computer scientists in a field that has been dramatically altered by the growth of the Web.<br><br>At every turn, the goal is practical: to show you how things you might need to do are already being done, or how they can be done. The first part of the book is devoted to technology and examines issues such as varying media requirements, indexing and classification, networks and distribution, and presentation. The second part of the book is concerned with the human contexts in which digital libraries function. Here youll find specific and useful information on usability, preservation, scientific applications, and thorny legal and economic questions.<br><br> Useful for digital library projects in all kinds of settings, including commercial and community ventures, museums, research institutions, and schools.<br> Covers the entire spectrum of media, including text, all kinds of images, audio, and video.<br> Provides practical advice on achieving the best of what is possible while avoiding common pitfalls.<br> Filled with case studies and references to valuable outside resources.} {This fully revised and updated second edition of Understanding Digital Libraries focuses on the challenges faced by both librarians and computer scientists in a field that has been dramatically altered by the growth of the Web. At every turn, the goal is practical: to show you how things you might need to do are already being done, or how they can be done. The first part of the book is devoted to technology and examines issues such as varying media requirements, indexing and classification, networks and distribution, and presentation. The second part of the book is concerned with the human contexts in which digital libraries function. Here you'll find specific and useful information on usability, preservation, scientific applications, and thorny legal and economic questions.}},\n author = {Michael Lesk},\n citeulike-article-id = {813763},\n citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\\&amp;path=ASIN/1558609245},\n citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\\&amp;path=ASIN/1558609245},\n citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\\&amp;path=ASIN/1558609245},\n citeulike-linkout-3 = {http://www.amazon.co.uk/exec/obidos/ASIN/1558609245/citeulike00-21},\n citeulike-linkout-4 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\\&path=ASIN/1558609245},\n citeulike-linkout-5 = {http://www.worldcat.org/isbn/1558609245},\n citeulike-linkout-6 = {http://books.google.com/books?vid=ISBN1558609245},\n citeulike-linkout-7 = {http://www.amazon.com/gp/search?keywords=1558609245\\&index=books\\&linkCode=qs},\n citeulike-linkout-8 = {http://www.librarything.com/isbn/1558609245},\n citeulike-linkout-9 = {http://www.worldcat.org/oclc/56911889},\n day = {02},\n howpublished = {Paperback},\n isbn = {1558609245},\n keyword = {digital\\_library},\n link = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/1558609245},\n month = {December},\n posted-at = {2010-04-20 20:57:09},\n priority = {0},\n publisher = {Elsevier},\n title = {Understanding digital libraries}\n}\n\n@article{ citeulike:850436,\n author = {P. D. Bruza and D. W. Song and K. F. Wong},\n citeulike-article-id = {850436},\n journal = {Journal of the American Society for Information Science},\n number = {12},\n pages = {1090--1105},\n posted-at = {2010-01-15 16:57:19},\n priority = {2},\n title = {Aboutness from a Commonsense Perspective},\n volume = {51}\n}\n\n@article{ citeulike:935556,\n abstract = {This essay is a personal analysis of information science as a field of scientific inquiry and professional practice that has evolved over the past half-century. Various sections examine the origin of information science in respect to the problems of information explosion; the social role of the field; the nature of ?information? in information science; the structure of the field in terms of problems addressed; evolutionary trends in information retrieval as a major branch of information science; the relation of information science to other fields, most notably librarianship and computer science; and educational models and issues. Conclusions explore some dominant trends affecting the field.},\n address = {School of Communication, Information and Library Studies, Rutgers University, 4 Huntington Street, New Brunswick, NJ 08903},\n author = {Tefko Saracevic},\n citeulike-article-id = {935556},\n citeulike-linkout-0 = {http://dx.doi.org/10.1002/(SICI)1097-4571(1999)50:12%3C1051::AID-ASI2%3E3.0.CO;2-Z},\n citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/69500811/ABSTRACT},\n doi = {10.1002/(SICI)1097-4571(1999)50:12%3C1051::AID-ASI2%3E3.0.CO;2-Z},\n journal = {Journal of the American Society for Information Science},\n keyword = {information\\_science},\n link = {http://dx.doi.org/10.1002/(SICI)1097-4571(1999)50:12%3C1051::AID-ASI2%3E3.0.CO;2-Z},\n number = {12},\n pages = {1051--1063},\n posted-at = {2009-09-07 02:22:51},\n priority = {0},\n title = {Information science},\n volume = {50},\n year = {1999}\n}\n\n@article{ citeulike:937809,\n abstract = {Metadata plays a key role in digital projects. This article introduces the six steps of metadata implementation for digital projects at the Pennsylvania State (Penn State) University Libraries: analyzing metadata requirements, adopting metadata schemes, creating metadata content, delivery and access, evaluation of metadata, and sustaining metadata maintenance. An array of technical, managerial, and organizational questions and issues of metadata implementation are discussed in the context of digital initiatives. The author proposes a coordinated metadata management approach based upon Penn State's experiences and best practices.},\n author = {Jin Ma},\n citeulike-article-id = {937809},\n doi = {10.1016/j.lcats.2006.07.001},\n journal = {Library Collections, Acquisitions, and Technical Services},\n keyword = {metadata},\n link = {http://dx.doi.org/10.1016/j.lcats.2006.07.001},\n month = {},\n number = {1-2},\n pages = {3--17},\n posted-at = {2009-07-01 20:52:37},\n priority = {0},\n title = {Managing metadata for digital projects},\n volume = {30},\n year = {2006}\n}\n\n@article{ citeulike:97070,\n abstract = {The paper discusses the notion of steps in indexing and reveals that the document-centered approach to indexing is prevalent and argues that the document-centered approach is problematic because it blocks out context-dependent factors in the indexing process. A domain-centered approach to indexing is presented as an alternative and the paper discusses how this approach includes a broader range of analyses and how it requires a new set of actions from using this approach; analysis of the domain, users and indexers. The paper concludes that the two-step procedure to indexing is insufficient to explain the indexing process and suggests that the domain-centered approach offers a guide for indexers that can help them manage the complexity of indexing.},\n author = {Jens-Erik Mai},\n citeulike-article-id = {97070},\n citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.ipm.2003.12.004},\n citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6VC8-4BN0DSN-2/2/041a56f590f2166e0305c00d5d311a73},\n doi = {10.1016/j.ipm.2003.12.004},\n journal = {Information Processing \\& Management},\n keyword = {indexers, metadata},\n link = {http://dx.doi.org/10.1016/j.ipm.2003.12.004},\n month = {May},\n number = {3},\n pages = {599--611},\n posted-at = {2009-12-02 00:14:15},\n priority = {2},\n title = {Analysis in indexing: document and domain centered approaches},\n volume = {41},\n year = {2005}\n}\n\n@article{ DBLP:ChongMSL03,\n author = {Quddus Chong and Anup Marwadi and Kaustubh Supekar and Yugyung Lee},\n bibsource = {DBLP, http://dblp.uni-trier.de},\n journal = {Journal of Research and Practice in Information Technology},\n number = {2},\n pages = {139--154},\n title = {Ontology Based Metadata Management in Medical Domains},\n volume = {35},\n year = {2003}\n}\n\n@inproceedings{ hooland_answeringcall_2008,\n abstract = {Although the issue of metadata quality is recognized as an important topic within the metadata research community, the cultural heritage sector has been slow to develop methodologies, guidelines and tools for addressing this topic in practice. This paper concentrates on metadata quality specifically within the museum sector and describes the potential of data-profiling techniques for metadata quality evaluation. A case study illustrates the application of a general-purpose data-profiling tool on a large collection of metadata records from an ethnographic collection. After an analysis of the results of the case-study the paper reviews further steps in our research and presents the implementation of a metadata quality tool within an open-source collection management software.},\n address = {Berlin, Germany},\n author = {Seth {van Hooland} and Yves Bontemps and Seth Kaufman},\n booktitle = {Proceedings of the 2008 International Conference on Dublin Core and Metadata Applications},\n citeulike-article-id = {6549325},\n citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1503418.1503428\\&\\\\#38;coll=GUIDE\\&\\\\#38;dl=GUIDE\\&\\\\#38;CFID=71452716\\&\\\\#38;CFTOKEN=28016179},\n keyword = {collection, data-profiling, file-import-10-01-16, management, metadata, quality, software},\n link = {http://portal.acm.org/citation.cfm?id=1503418.1503428&coll=GUIDE&dl=GUIDE&CFID=71452716&CFTOKEN=28016179},\n pages = {93--103},\n posted-at = {2010-01-16 02:40:47},\n priority = {2},\n publisher = {Dublin Core Metadata Initiative},\n title = {Answering the call for more accountability: applying data profiling to museum metadata}\n}\n\n@article{ unpublished:elenatorou,\n author = {Torou Akrivi Katifori Elena and Vassilakis Costas},\n keyword = {digital\\_museum, information\\_visualization, ontology},\n link = {http://oceanis.mm.di.uoa.gr/pened/papers/7-onto-meth.pdf},\n posted-at = {2009-06-04 21:08:17},\n priority = {3},\n title = {Creating an Historical Archive Ontology: Guidelines and Evalation},\n year = {2006}\n}\n\n"
